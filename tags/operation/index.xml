<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>operation on forest nook</title><link>/diary/tags/operation/</link><description>Recent content in operation on forest nook</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><copyright>© 2021 Tetsuya Morimoto</copyright><lastBuildDate>Fri, 26 Aug 2022 12:03:43 +0900</lastBuildDate><atom:icon>/diary/favicon.ico</atom:icon><icon>/diary/favicon.ico</icon><atom:link href="/diary/tags/operation/index.xml" rel="self" type="application/rss+xml"/><item><title>簡単な現象の組み合わせ障害</title><link>/diary/posts/2022/0826/</link><pubDate>Fri, 26 Aug 2022 12:03:43 +0900</pubDate><guid>/diary/posts/2022/0826/</guid><description>0時に寝て6時に起きた。
eks クラスター障害の原因判明 過去に2回発生していた eks クラスター障害 の原因がようやくわかった。テスト環境も本番環境は5日ごとに再現していて、datadog で k8s のダッシュボードでそれぞれの pod 単位のメモリ使用量をみると datadog-agent の pod がメモリリークしていることに気付いた。そこから当たりをつけて datadog-agent の issue を調べると次のバグに遭遇していた。
[BUG] agent leaves defunct processes with version 7.38.0 #12997 ゾンビプロセスが生成されて、それが os のプロセス数上限に達してしまい、それによってプロセス (スレッド) が生成できなくなって、その結果として aws/amazon-vpc-cni-k8s の aws-node という eks クラスターの管理アプリケーションが動かなくなって、それが動かないと k8s ノードのステータスが NotReady になってしまって、通常の pod のアプリケーションも動かなくなってしまうという現象が発生していた。datadog-agent のアップグレードは私が行ったものだし、その後の k8s ノードの監視や調査で気付きが足りなかったと反省した。
datadog-agent の新しいバージョンをテスト環境でもうしばらく検証してもよかった datadog-agent をリソースリークの可能性を私の中の調査対象から外していた 世の中で使われているものに致命的なバグが起きないだろうという先入観があった プロセスを生成できない原因として考えられる背景を調査すべきだった ulimit を確認してリソース制限はないようにみえた プロセス数やゾンビプロセスを調べていなかった kernel に /proc/sys/kernel/pid_max という上限設定があることを知らなかった テスト環境と本番環境で5日程度で落ちるという周期性から気付くべきだった たしかにテスト環境から1日遅れて本番環境で障害が発生していた 周期性があることでリソースリークの可能性は高いとすぐに調査すべきだった datadog で k8s のダッシュボードを調べるべきだった すでに用意されているものがあったのでみようと思えばみえた aws のインフラ要因ではないかと疑っていた ごめんなさい これは悔しい。自分の無能さや気付きの低さを実感した事件だった。私が注意深く観察していればもう1週間早く気付けた。そのせいで余分な障害と調査に時間を費やした。1つ1つは全く難しくない現象が巧妙に絡みあって隠蔽された結果としての状況に気付けなかった。注意して1つずつ観察して追跡していけばすぐに気付けた。本当に悔しい。</description><content>&lt;p>0時に寝て6時に起きた。&lt;/p>
&lt;h2 id="eks-クラスター障害の原因判明">eks クラスター障害の原因判明&lt;/h2>
&lt;p>&lt;a href="/diary/diary/posts/2022/0820/#aws-インフラの調子が悪い">過去に2回発生していた eks クラスター障害&lt;/a> の原因がようやくわかった。テスト環境も本番環境は5日ごとに再現していて、datadog で k8s のダッシュボードでそれぞれの pod 単位のメモリ使用量をみると datadog-agent の pod がメモリリークしていることに気付いた。そこから当たりをつけて datadog-agent の issue を調べると次のバグに遭遇していた。&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/DataDog/datadog-agent/issues/12997">[BUG] agent leaves defunct processes with version 7.38.0 #12997&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>ゾンビプロセスが生成されて、それが os のプロセス数上限に達してしまい、それによってプロセス (スレッド) が生成できなくなって、その結果として &lt;a href="https://github.com/aws/amazon-vpc-cni-k8s">aws/amazon-vpc-cni-k8s&lt;/a> の &lt;code>aws-node&lt;/code> という eks クラスターの管理アプリケーションが動かなくなって、それが動かないと k8s ノードのステータスが NotReady になってしまって、通常の pod のアプリケーションも動かなくなってしまうという現象が発生していた。datadog-agent のアップグレードは私が行ったものだし、その後の k8s ノードの監視や調査で気付きが足りなかったと反省した。&lt;/p>
&lt;ul>
&lt;li>datadog-agent の新しいバージョンをテスト環境でもうしばらく検証してもよかった&lt;/li>
&lt;li>datadog-agent をリソースリークの可能性を私の中の調査対象から外していた
&lt;ul>
&lt;li>世の中で使われているものに致命的なバグが起きないだろうという先入観があった&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>プロセスを生成できない原因として考えられる背景を調査すべきだった
&lt;ul>
&lt;li>ulimit を確認してリソース制限はないようにみえた&lt;/li>
&lt;li>プロセス数やゾンビプロセスを調べていなかった&lt;/li>
&lt;li>kernel に &lt;code>/proc/sys/kernel/pid_max&lt;/code> という上限設定があることを知らなかった&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>テスト環境と本番環境で5日程度で落ちるという周期性から気付くべきだった
&lt;ul>
&lt;li>たしかにテスト環境から1日遅れて本番環境で障害が発生していた&lt;/li>
&lt;li>周期性があることでリソースリークの可能性は高いとすぐに調査すべきだった&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>datadog で k8s のダッシュボードを調べるべきだった
&lt;ul>
&lt;li>すでに用意されているものがあったのでみようと思えばみえた&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>aws のインフラ要因ではないかと疑っていた
&lt;ul>
&lt;li>ごめんなさい&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>これは悔しい。自分の無能さや気付きの低さを実感した事件だった。私が注意深く観察していればもう1週間早く気付けた。そのせいで余分な障害と調査に時間を費やした。1つ1つは全く難しくない現象が巧妙に絡みあって隠蔽された結果としての状況に気付けなかった。注意して1つずつ観察して追跡していけばすぐに気付けた。本当に悔しい。&lt;/p>
&lt;p>1つだけ言い訳をさせてもらうと、私は本番環境にアクセスできない。だからテスト環境と本番環境で発生している現象が同じかどうかを判断できず、調査を進める確証をもてなかった。&lt;/p></content></item><item><title>vuejs の template 調査</title><link>/diary/posts/2022/0824/</link><pubDate>Wed, 24 Aug 2022 07:58:08 +0900</pubDate><guid>/diary/posts/2022/0824/</guid><description>0時に寝て6時に起きた。
連日のサービスイン作業 引き続きサービスインの運用対応は大変そうでちゃんと検証していない修正を慌ててマージしようとしているからテスト環境まで壊れてて関係ない開発にも影響が出ていた。今日も別の施設のサービスインだったらしくて、ある機能がないとそのサービスインの切り替え作業ができないという話しだったそうで、当日に慌てて pr を作ってマージしてた。先週からわかっていた必要な機能を実装してなくて、週末は残業も休出もしてなくて、今日になって慌てて修正してマージしてた。昔の開発と比べてがんばっててできないのではなくて、いまの開発はがんばってないからできないという雰囲気になったなという印象。
vuejs の template と expression あるフォームのコンポーネントを作ろうと思って interface を定義していてデフォルト値をテンプレート側に指定できるといいんじゃないかと考えた。というのは typescript の interface のメンバーは値を保持できないから。例えば、次のようなコードで :cols=&amp;quot;item.col ?? 2&amp;quot; のように表現できたら嬉しいように思う。
&amp;lt;v-row dense v-for=&amp;#34;item in conditions&amp;#34; :key=&amp;#34;item.label&amp;#34;&amp;gt; &amp;lt;v-col :cols=&amp;#34;item.col ?? 2&amp;#34;&amp;gt; {{ element }} &amp;lt;/v-col&amp;gt; &amp;lt;/v-row&amp;gt; 余談だけど、?? は null 合体演算子という名前は知っていたけど、これを英語で何と呼ぶのか知らなかった。Nullish coalescing operator と言う。ググってみると vuejs の issue でもそこそこ議論されていて vue3 からサポートするとしながら、根強い要望があるのか？ vue2 でも 2.7 でサポートしたらしい。こういうモダンな javascript の expression を ESNext syntax と呼んだりするみたい。それすらも知らなかった。
Optional chaining in templates does not seem to work #11088 たまたまうちで使っているのは vue 2.</description><content>&lt;p>0時に寝て6時に起きた。&lt;/p>
&lt;h2 id="連日のサービスイン作業">連日のサービスイン作業&lt;/h2>
&lt;p>引き続きサービスインの運用対応は大変そうでちゃんと検証していない修正を慌ててマージしようとしているからテスト環境まで壊れてて関係ない開発にも影響が出ていた。今日も別の施設のサービスインだったらしくて、ある機能がないとそのサービスインの切り替え作業ができないという話しだったそうで、当日に慌てて pr を作ってマージしてた。先週からわかっていた必要な機能を実装してなくて、週末は残業も休出もしてなくて、今日になって慌てて修正してマージしてた。昔の開発と比べてがんばっててできないのではなくて、いまの開発はがんばってないからできないという雰囲気になったなという印象。&lt;/p>
&lt;h2 id="vuejs-の-template-と-expression">vuejs の template と expression&lt;/h2>
&lt;p>あるフォームのコンポーネントを作ろうと思って interface を定義していてデフォルト値をテンプレート側に指定できるといいんじゃないかと考えた。というのは typescript の interface のメンバーは値を保持できないから。例えば、次のようなコードで &lt;code>:cols=&amp;quot;item.col ?? 2&amp;quot;&lt;/code> のように表現できたら嬉しいように思う。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-xml" data-lang="xml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;v-row&lt;/span> &lt;span style="color:#960050;background-color:#1e0010">dense&lt;/span> &lt;span style="color:#a6e22e">v-for=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;item in conditions&amp;#34;&lt;/span> &lt;span style="color:#a6e22e">:key=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;item.label&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;lt;v-col&lt;/span> &lt;span style="color:#a6e22e">:cols=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;item.col ?? 2&amp;#34;&lt;/span>&lt;span style="color:#f92672">&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {{ element }}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#f92672">&amp;lt;/v-col&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#f92672">&amp;lt;/v-row&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>余談だけど、&lt;code>??&lt;/code> は null 合体演算子という名前は知っていたけど、これを英語で何と呼ぶのか知らなかった。&lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Nullish_coalescing_operator">Nullish coalescing operator&lt;/a> と言う。ググってみると vuejs の issue でもそこそこ議論されていて vue3 からサポートするとしながら、根強い要望があるのか？ vue2 でも 2.7 でサポートしたらしい。こういうモダンな javascript の expression を ESNext syntax と呼んだりするみたい。それすらも知らなかった。&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/vuejs/vue/issues/11088">Optional chaining in templates does not seem to work #11088&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>たまたまうちで使っているのは vue 2.6.14 なので vue 2.7 で動くのかどうか検証できないけど、いま使っている nuxtjs2 との依存関係があるのでそれ次第で vue 2.7 にアップグレードの可否が決まるらしい。全然フロントエンドの開発がわからないので、こういう基本的なところで引っかかると背景を調べるのに時間がかかる。&lt;/p></content></item><item><title>週明けのサービスイン</title><link>/diary/posts/2022/0822/</link><pubDate>Mon, 22 Aug 2022 08:27:42 +0900</pubDate><guid>/diary/posts/2022/0822/</guid><description>0時に寝て7時に起きた。
3つ目のサービスイン またまた私は勘違いしていて明日だと思っていたら今日が3つ目のサービスインだった。約1ヶ月ぶりのサービスイン になる。もう3回目なので要領よく切り替え作業やるのかなと眺めてたけど、新たなトラブルもいくつかあって、これまで同様、ドタバタしているようにみえる。私は本番環境にアクセスできないので何かトラブルがあっても聞いた内容から類推で助言を述べるしかできず、とはいえ、何かあったら質問がくるかもしれないからハドルに入って成り行きを見守ってないといけない。とくに手伝うこともないのにメンバーの作業が完了するまで待ってないといけない。この切り替え作業や運用対応をやっていると要件定義やコードレビューなどは放置されるのでまた作業のスケジュールが先送りになる。私は別に困らないけど、しばらくだらだらした開発が続く。</description><content>&lt;p>0時に寝て7時に起きた。&lt;/p>
&lt;h2 id="3つ目のサービスイン">3つ目のサービスイン&lt;/h2>
&lt;p>またまた私は勘違いしていて明日だと思っていたら今日が3つ目のサービスインだった。&lt;a href="/diary/diary/posts/2022/0719/#2つ目のサービスイン">約1ヶ月ぶりのサービスイン&lt;/a> になる。もう3回目なので要領よく切り替え作業やるのかなと眺めてたけど、新たなトラブルもいくつかあって、これまで同様、ドタバタしているようにみえる。私は本番環境にアクセスできないので何かトラブルがあっても聞いた内容から類推で助言を述べるしかできず、とはいえ、何かあったら質問がくるかもしれないからハドルに入って成り行きを見守ってないといけない。とくに手伝うこともないのにメンバーの作業が完了するまで待ってないといけない。この切り替え作業や運用対応をやっていると要件定義やコードレビューなどは放置されるのでまた作業のスケジュールが先送りになる。私は別に困らないけど、しばらくだらだらした開発が続く。&lt;/p></content></item><item><title>休日の本番障害</title><link>/diary/posts/2022/0820/</link><pubDate>Sat, 20 Aug 2022 12:17:43 +0900</pubDate><guid>/diary/posts/2022/0820/</guid><description>夕方から寝ていて何度か起きたものの、そのままずっと寝ていた。あまりないことなんだけど、珍しくたくさん眠れた。
ストレッチ 今日の開脚幅は開始前160cmで、ストレッチ後163cmだった。計測の仕方がややいい加減だった気もしたが、先週より少しよくなったということにしておく。右腰の張りが強いのと肩が前に入りがちなので肩を開いて姿勢を保つように心がけるとよいとアドバイスをいただいた。もう通い始めて1年半ぐらい経つ。トレーナーさんも大半が入れ替わっていて通い始めたときに話しかけてくれた私が知っているトレーナーさんはほとんどいない。1年半も経つと人は変わっていくなというのを実感している。私の最初のトレーナーさんは社内制度で別の店舗の助っ人に行っているのでいなくなった人たちが辞めているわけでもないとは思うけど、1-2年で人が入れ替わってもサービスは継続していかないといけないし、会社ってそういうものだなと実感する機会でもある。
aws インフラの調子が悪い？ 1-2週間ぐらい前からテスト環境を含めると複数回発生している eks クラスターの障害 がたまたま土曜日の夜という休日に発生した。いま eks クラスターのインフラの振る舞いを把握しているのは私だけなので、気付いてから指示を出して問題が発生している k8s ノードの削除 (ec2 インスタンスの削除) で復旧させるワークアラウンドで復旧させた。私は本番環境にアクセスできないので詳しい調査はできない。状況を正しく把握できてはいないけれど、k8s ノードが死んだり生き返ったりする不安定な状況に発生しているらしく、k8s ノードを削除して新規に作り直すと復旧することがわかっている。NotReady と Ready を繰り返したりしてアプリケーションの振る舞いが不安定になる。NotReady,SchedulingDisabled になれば、おそらく drain して k8s ノードが入れ替わってくれるのだけど、そうならない不安定な状況があるみたい。これ以上の調査は aws のサポートに問い合わせないとわからない。</description><content>&lt;p>夕方から寝ていて何度か起きたものの、そのままずっと寝ていた。あまりないことなんだけど、珍しくたくさん眠れた。&lt;/p>
&lt;h2 id="ストレッチ">ストレッチ&lt;/h2>
&lt;p>今日の開脚幅は開始前160cmで、ストレッチ後163cmだった。計測の仕方がややいい加減だった気もしたが、先週より少しよくなったということにしておく。右腰の張りが強いのと肩が前に入りがちなので肩を開いて姿勢を保つように心がけるとよいとアドバイスをいただいた。もう通い始めて1年半ぐらい経つ。トレーナーさんも大半が入れ替わっていて通い始めたときに話しかけてくれた私が知っているトレーナーさんはほとんどいない。1年半も経つと人は変わっていくなというのを実感している。私の最初のトレーナーさんは社内制度で別の店舗の助っ人に行っているのでいなくなった人たちが辞めているわけでもないとは思うけど、1-2年で人が入れ替わってもサービスは継続していかないといけないし、会社ってそういうものだなと実感する機会でもある。&lt;/p>
&lt;h2 id="aws-インフラの調子が悪い">aws インフラの調子が悪い？&lt;/h2>
&lt;p>1-2週間ぐらい前からテスト環境を含めると複数回発生している &lt;a href="/diary/diary/posts/2022/0815/">eks クラスターの障害&lt;/a> がたまたま土曜日の夜という休日に発生した。いま eks クラスターのインフラの振る舞いを把握しているのは私だけなので、気付いてから指示を出して問題が発生している k8s ノードの削除 (ec2 インスタンスの削除) で復旧させるワークアラウンドで復旧させた。私は本番環境にアクセスできないので詳しい調査はできない。状況を正しく把握できてはいないけれど、k8s ノードが死んだり生き返ったりする不安定な状況に発生しているらしく、k8s ノードを削除して新規に作り直すと復旧することがわかっている。NotReady と Ready を繰り返したりしてアプリケーションの振る舞いが不安定になる。NotReady,SchedulingDisabled になれば、おそらく drain して k8s ノードが入れ替わってくれるのだけど、そうならない不安定な状況があるみたい。これ以上の調査は aws のサポートに問い合わせないとわからない。&lt;/p></content></item><item><title>k8s ノードの削除方法がわからない</title><link>/diary/posts/2022/0815/</link><pubDate>Mon, 15 Aug 2022 08:12:40 +0900</pubDate><guid>/diary/posts/2022/0815/</guid><description>1時に寝て7時に起きた。寝冷えしてお腹痛い。
eks クラスターの障害 日曜日にテスト環境の eks クラスターで障害が発生していた。k8s ノードが NotReady になっていて、しばらくすると NotReady,SchedulingDisabled に変わって、それから新しい k8s ノードが起動して古いものが削除されて置き換わった。おそらくエラーが発生し始めてから1時間ほどはかかっていたと思う。わりと時間がかかるので明らかに k8s ノードが不調だと人間が判断しているなら ec2 インスタンスの切り替えを早くやりたい。k8s の公式ドキュメントの Use kubectl drain to remove a node from service では次の手順で行うように書いてある。
$ kubectl drain &amp;lt;node name&amp;gt; drain が正常終了すれば安全に k8s ノードを削除してよいのかな？
$ kubectl delete node &amp;lt;node name&amp;gt; eks クラスターで障害が発生していたときに drain を実行するとエラーになったのでそのまま delete node したら k8s ノードは削除されたものの、自動的に新しい k8s ノードが起動しなかった。aws のマネジメントコンソールから ec2 インスタンスを調べたら起動したままだったので強制的に ec2 インスタンスを終了させたところ、オートスケールの設定から ec2 インスタンスが起動してきて復旧した。但し、このやり方は k8s が意図した手順ではないようにも思える。軽く調べた範囲では k8s ノードの正しい削除方法 (置き換え方法？) がみつからなかった。そんなことを日曜日に確認していたら月曜日にほぼ同じ現象が本番環境の eks クラスターでも発生した。私は一度経験していたので同僚に指示して経過を観察していた。ここで書いたのと同じような手順で復旧した。おそらく aws 側のなにかのメンテナンス作業でうちの eks クラスターだと k8s ノードが死んでしまうような作業があったのではないか？と疑いをもっている。</description><content>&lt;p>1時に寝て7時に起きた。寝冷えしてお腹痛い。&lt;/p>
&lt;h2 id="eks-クラスターの障害">eks クラスターの障害&lt;/h2>
&lt;p>日曜日にテスト環境の eks クラスターで障害が発生していた。k8s ノードが NotReady になっていて、しばらくすると NotReady,SchedulingDisabled に変わって、それから新しい k8s ノードが起動して古いものが削除されて置き換わった。おそらくエラーが発生し始めてから1時間ほどはかかっていたと思う。わりと時間がかかるので明らかに k8s ノードが不調だと人間が判断しているなら ec2 インスタンスの切り替えを早くやりたい。k8s の公式ドキュメントの &lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/#use-kubectl-drain-to-remove-a-node-from-service">Use kubectl drain to remove a node from service&lt;/a> では次の手順で行うように書いてある。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl drain &amp;lt;node name&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>drain が正常終了すれば安全に k8s ノードを削除してよいのかな？&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ kubectl delete node &amp;lt;node name&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>eks クラスターで障害が発生していたときに drain を実行するとエラーになったのでそのまま delete node したら k8s ノードは削除されたものの、自動的に新しい k8s ノードが起動しなかった。aws のマネジメントコンソールから ec2 インスタンスを調べたら起動したままだったので強制的に ec2 インスタンスを終了させたところ、オートスケールの設定から ec2 インスタンスが起動してきて復旧した。但し、このやり方は k8s が意図した手順ではないようにも思える。軽く調べた範囲では k8s ノードの正しい削除方法 (置き換え方法？) がみつからなかった。そんなことを日曜日に確認していたら月曜日にほぼ同じ現象が本番環境の eks クラスターでも発生した。私は一度経験していたので同僚に指示して経過を観察していた。ここで書いたのと同じような手順で復旧した。おそらく aws 側のなにかのメンテナンス作業でうちの eks クラスターだと k8s ノードが死んでしまうような作業があったのではないか？と疑いをもっている。&lt;/p></content></item></channel></rss>