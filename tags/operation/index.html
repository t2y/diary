<!doctype html><html lang=en><head><title>operation :: forest nook</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=/diary/tags/operation/><link rel=stylesheet href=/diary/styles.css><link rel=stylesheet href=/diary/style.css><link rel="shortcut icon" href=/diary/favicon.ico><meta name=twitter:card content="summary"><meta name=twitter:site content="t2y"><meta name=twitter:creator content><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:title" content="operation"><meta property="og:description" content><meta property="og:url" content="/diary/tags/operation/"><meta property="og:site_name" content="forest nook"><meta property="og:image" content="/diary/favicon.ico"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="627"><link href=/diary/tags/operation/index.xml rel=alternate type=application/rss+xml title="forest nook"></head><body class=green><div class="container full headings--one-size"><header class=header><div class=header__inner><div class=header__logo><a href=/diary><div class=logo>forest nook</div></a></div><ul class="menu menu--mobile"><li class=menu__trigger>Menu&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=/diary/about>自己紹介</a></li><li><a href=/diary/dates>月別一覧</a></li><li><a href=/diary/tags>タグ一覧</a></li></ul></li></ul></div><nav class=navigation-menu><ul class="navigation-menu__inner menu--desktop"><li><a href=/diary/about>自己紹介</a></li><li><a href=/diary/dates>月別一覧</a></li><li><a href=/diary/tags>タグ一覧</a></li></ul></nav></header><div class=content><div class=posts><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2023/0714/>メモリリークに遭遇</a></h1><div class=post-meta><time class=post-date>2023-07-14 (Fri.) ::</time></div><span class=post-tags>#<a href=/diary/tags/operation/>operation</a>&nbsp;
#<a href=/diary/tags/testing/>testing</a>&nbsp;
#<a href=/diary/tags/go/>go</a>&nbsp;
#<a href=/diary/tags/design/>design</a>&nbsp;</span><div class=post-content><p>23時に寝て何度か起きて5時に起きてからだらだらネットしながら記事を読んだりしていて7時に起き上がった。</p><h2 id=agent-アプリケーションのメモリリーク調査>agent アプリケーションのメモリリーク調査</h2><p>qa テストの一環として先月からテスト環境で毎分 agent アプリケーションにリクエストを投げる長時間稼働テストを実行している。なんとなく気になるところがあったからやったわけではあるけれど、長時間稼働テストによってメモリリークを検出できてしまった。自分を過信せずちゃんと検証しないといけないなと思えた。top コマンドの実メモリー (RES) を1ヶ月前と比較して増えているからメモリリークだと気付いたところ。これからメモリプロファイリングをしながら原因を追求していく。私が書いた (レビューした) go のコードでメモリリークはないだろうと高をくくっていただけにちょっとショックではあった。</p><p>go は標準ライブラリに pprof というプロファイラがあるので簡単にデバッグできる。プロファイラで昨日から調査していたところ、<a href=https://github.com/go-zeromq/zmq4>go-zeromq/zmq4</a> の処理でメモリリークしていることはわかった。それがライブラリの使い方が誤っているのか、潜在的な不具合なのかはまだこれから調査するところ。</p><p>ライブラリ側の問題を調査するので厄介ではあるけど、私が書いた (レビューした) go のコードでメモリリークしているわけじゃないことがわかって少しほっとした。</p><h2 id=go-の-generics-勉強会>go の generics 勉強会</h2><p><a href="/diary/posts/2023/0707/#go-の-generics 勉強会の準備">先日準備した資料</a> を使って勉強会を開催した。</p><ul><li><a href=https://github.com/t2y/go-generics-study>https://github.com/t2y/go-generics-study</a></li></ul><p>この勉強会はある意味、うちのチームのメンバーが理解しておくべき内容なので go のプログラミングをやっていないメンバーが聞いてもあまり関心をもてない内容となっている。そういうお断りもした上で最悪2-3人ぐらいの参加者になるかと思ったもののプログラミングに関心がある人たちは参加してくれて5-6人ぐらいの規模にはなった。一方で内容も難しいし、私の説明がどれだけわかりやすかったか、私自身にはわからないのでなんとも言えない。質問も一切なかったので喋りきって疲れたという疲労感と、伝わったのか伝わらなかったのか分からない消化不良感と、金曜日だから今日はもういいや感でどっと疲れたというのが率直な感想になる。</p><p>とはいえ、私もずっと generics の仕様をちゃんと追いかけたいと思いながら先送りしていたものではあるので私の中では自分が go の generics の理解度をあげて実際の開発の中で使い分けるだけの判断基準をもてたことが収穫だったと言える。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2023/0621/>厄介なインフラ問題をやっつけた</a></h1><div class=post-meta><time class=post-date>2023-06-21 (Wed.) ::</time></div><span class=post-tags>#<a href=/diary/tags/infrastructure/>infrastructure</a>&nbsp;
#<a href=/diary/tags/operation/>operation</a>&nbsp;
#<a href=/diary/tags/podman/>podman</a>&nbsp;
#<a href=/diary/tags/event/>event</a>&nbsp;</span><div class=post-content><p>2時に寝て6時に起きて7時に起きた。夜に作業していたら遅くなった。</p><h2 id=厄介なインフラの問題-解決編>厄介なインフラの問題 解決編</h2><p><a href=/diary/posts/2023/0619/#運用のトラブルシューティング>運用のトラブルシューティング</a> の続き。アプリケーションアカウントを作って compose 環境を構築したら nginx のコンテナが起動して即時終了する状態になったという。これまで起きていた現象とまた違う問題が発生してさらに混迷をもたらすかに思えたが、私の中では nginx のコンテナでなにかがおかしいと問題の発生箇所を局所化できたのでそこからの調査はそんなに時間を必要としなかった。</p><p>結論からいうと podman の <a href=https://github.com/containers/aardvark-dns>aardvark-dns</a> の不具合だった。なんらかのトリガーでコンテナネットワーク内の名前解決が不整合な状態に陥る。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>vagrant@bookworm:$ podman-compose exec proxy /bin/bash
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>root@3742c45c7c60:/# dig app
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>; &lt;&lt;&gt;&gt; DiG 9.16.37-Debian &lt;&lt;&gt;&gt; app
</span></span><span style=display:flex><span>;; global options: +cmd
</span></span><span style=display:flex><span>;; Got answer:
</span></span><span style=display:flex><span>;; -&gt;&gt;HEADER<span style=color:#e6db74>&lt;&lt;- opco</span>de: QUERY, status: NOERROR, id: <span style=color:#ae81ff>56696</span>
</span></span><span style=display:flex><span>;; flags: qr rd ra ad; QUERY: 1, ANSWER: 8, AUTHORITY: 0, ADDITIONAL: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>;; OPT PSEUDOSECTION:
</span></span><span style=display:flex><span>; EDNS: version: 0, flags:; udp: <span style=color:#ae81ff>4096</span>
</span></span><span style=display:flex><span>; COOKIE: 37ff0fd63315d70e <span style=color:#f92672>(</span>echoed<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>;; QUESTION SECTION:
</span></span><span style=display:flex><span>;app.				IN	A
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>;; ANSWER SECTION:
</span></span><span style=display:flex><span>app.			86400	IN	A	10.89.0.36
</span></span><span style=display:flex><span>app.			86400	IN	A	10.89.0.36
</span></span><span style=display:flex><span>app.			86400	IN	A	10.89.0.136
</span></span><span style=display:flex><span>app.			86400	IN	A	10.89.0.136
</span></span><span style=display:flex><span>app.			86400	IN	A	10.89.0.146
</span></span><span style=display:flex><span>app.			86400	IN	A	10.89.0.146
</span></span><span style=display:flex><span>app.			86400	IN	A	10.89.0.156
</span></span><span style=display:flex><span>app.			86400	IN	A	10.89.0.156
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>;; Query time: <span style=color:#ae81ff>4</span> msec
</span></span><span style=display:flex><span>;; SERVER: 10.89.0.1#53<span style=color:#f92672>(</span>10.89.0.1<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>;; WHEN: Thu Jun <span style=color:#ae81ff>22</span> 02:45:26 UTC <span style=color:#ae81ff>2023</span>
</span></span><span style=display:flex><span>;; MSG SIZE  rcvd: <span style=color:#ae81ff>172</span>
</span></span></code></pre></div><p>podman 4.0 から aardvark-dns がコンテナネットワーク内での dns を提供する。nginx が app を名前解決したときに起動しているコンテナの ip アドレスではなく、削除された過去のコンテナの ip アドレスが返される状況が発生する。app という名前に対して複数の ip アドレスが返る。</p><p>このとき nginx は複数の ip アドレスのうちの1つに接続しようとするが、正しい ip アドレスでない場合、リクエストがタイムアウトする。タイムアウトした後に fallback で他の ip アドレスに接続しにいく。このときに正しい ip アドレスがみつかればクライアントにレスポンスが返る。この fallback のリトライの回数分だけリクエストのレイテンシの時間がかかっていた。</p><pre tabindex=0><code>vagrant@bookworm:$ podman logs -f proxy
...
2023/06/22 02:46:26 [error] 15#15: *41 connect() failed (113: No route to host) while connecting to upstream, client: 10.89.0.38, server: ucidmsv1-app, request: &#34;GET / HTTP/1.1&#34;, upstream: &#34;http://10.89.0.136:3000/&#34;, host: &#34;localhost:4430&#34;
2023/06/22 02:46:29 [error] 15#15: *41 connect() failed (113: No route to host) while connecting to upstream, client: 10.89.0.38, server: ucidmsv1-app, request: &#34;GET / HTTP/1.1&#34;, upstream: &#34;http://10.89.0.156:3000/&#34;, host: &#34;localhost:4430&#34;
2023/06/22 02:46:32 [error] 15#15: *41 connect() failed (113: No route to host) while connecting to upstream, client: 10.89.0.38, server: ucidmsv1-app, request: &#34;GET / HTTP/1.1&#34;, upstream: &#34;http://10.89.0.136:3000/&#34;, host: &#34;localhost:4430&#34;
10.89.0.38 - - [22/Jun/2023:02:46:32 +0000] &#34;GET / HTTP/1.1&#34; 200 2864 &#34;-&#34; &#34;curl/7.88.1&#34;
</code></pre><p>ワークアラウンドとして、次のファイルに複数の app の ip アドレスが登録されていれば不整合な状態なのでネットワークを削除して、このファイルも手動で削除してしまえばよい。</p><pre tabindex=0><code>$ cat /run/user/$(id -u)/containers/networks/aardvark-dns/mynetwork
</code></pre><p>ファイルを監視していると、どうやら mynetwork ファイルから名前と ip アドレスの情報が削除されるのは該当のコンテナが削除されるタイミングになる。なんらかのエラーにより、コンテナ削除時にマッピングの削除が実行されないと、古いコンテナのマッピング設定が残ったままとなり、compose サービスを起動したときに複数の ip アドレスの名前解決できる状態になってしまう。ちょっと調べても aardvark-dns に関する issue はたくさん登録されている。</p><ul><li><a href=https://github.com/containers/podman/issues/18783>https://github.com/containers/podman/issues/18783</a></li><li><a href=https://github.com/containers/podman/issues/18530>https://github.com/containers/podman/issues/18530</a></li><li><a href=https://github.com/containers/podman/issues/17370>https://github.com/containers/podman/issues/17370</a></li></ul><h2 id=コワーキングのオンラインイベント>コワーキングのオンラインイベント</h2><p>月例のカフーツさんのオンラインイベントに参加した。<a href=/diary/posts/2023/0517/#コワーキングのオンラインイベント>先月の所感はここ</a> 。今日はもともと予定していた話しをする参加者が急遽参加できなくなってしまったので他の参加者での雑談会になった。</p><p>いとうさん曰く、これまで外国人のデジタルノマドは自分で業務時間を選べるフリーランスの、さらにお金に余裕をもった人たちが多いと考えられていた。しかし、実際にコワーキングスペースに来られている外国人にキャリアを伺うと、大企業の普通の社員であることがわかってきた。グローバルな会社だと、働く場所に制限のない会社もあって、ただ日本へ行ってみたかった的な理由で日本へ来られて数ヶ月滞在して普通に会社のお仕事をするといったデジタルノマドもいるという。過去に私が働いていた職場の同僚も、コロナのときに会社がフルリモートワークの体制を設けて、airbnb で全国を旅しながら1年ほど働いていた。日本でもそういう社員はいるのだから外国人はなおさらという感じ。</p><p>そういった外国人のデジタルノマドが要求することが3つある。</p><ul><li>24時間利用できること (勤め先の会社と時差があるから)</li><li>セカンドモニターがあること</li><li>・・・ (あともう1つあったが、忘れてしまった)</li></ul><p>コワーキングスペースに外国人のデジタルノマドを呼び込むにはどうすればよいか。実際にコワーキングスペースへ来られた外国人に理由を伺うと英語のホームページをみて来ましたということらしい。至極、当たり前の話し。英語のホームページをちゃんと作ろうねみたいな話題で話していた。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2023/0619/>運用トラブルの調査</a></h1><div class=post-meta><time class=post-date>2023-06-19 (Mon.) ::</time></div><span class=post-tags>#<a href=/diary/tags/infrastructure/>infrastructure</a>&nbsp;
#<a href=/diary/tags/operation/>operation</a>&nbsp;
#<a href=/diary/tags/web-design/>web design</a>&nbsp;</span><div class=post-content><p>0時に寝て5時に起きて7時に起きた。もう暑くて家でもエアコンを解禁した。エアコンがあると寝心地が違う、快適。</p><h2 id=運用のトラブルシューティング>運用のトラブルシューティング</h2><p><a href=/diary/posts/2023/0613/#厄介なインフラの問題-x-2>厄介なインフラの問題</a> のクリティカルな方から着手し始めた。<a href=https://github.com/containers/podman-compose>podman-compose</a> を使って rootless な環境構築をやってみたところ、nginx を tls 終端としてリバースプロキシとするアプリケーションサーバーとの通信が数回に1回ぐらいの頻度で遅くなる。通常は 100msec 程度でレスポンスが返るのが数秒から数十秒かかる。</p><p>もともと podman-compose はサポート対象外なのでそんながんばる必要はない。しかし、これも調査の過程でコンテナの技術を学ぶ1つだと考え再現環境を構築しようとした。vagrant の debian 12 と podman-compose をインストールして同様に環境構築してみたが、仮想環境では再現しない。どうやら環境要因のようだ。そこで問題が発生しているマシンで私のアカウントで環境構築してみたが、やはり再現しない。なんと個人アカウントの違いによって起きる現象のようだ。また質が悪いのは私のアカウントでは再現しないが、メンバー2人のアカウントでは再現している。一般ユーザーから他人のユーザーのプロセスやコンテナの情報にアクセスできるわけがないので調査ができない。個人アカウントで compose 環境を構築するのは諦めてアプリケーションアカウントを作ってやりましょうという話しにした。アプリケーションアカウントで再現すれば調査するし、再現しなければこんな環境要因のトラブルシューティングの優先度を下げてもいいかなぁとも考えている。どうなるかなぁ。</p><h2 id=サイトデザインのサンプルページ>サイトデザインのサンプルページ</h2><p><a href=/diary/posts/2023/0522/#サイトデザイン打ち合わせ>サイトデザイン打ち合わせ</a> の続き。実際のサンプルが出てきたのでデザインの雰囲気やコードも含めて確認していく。ざっとサンプルページを確認した。デザインはとても気に入っている。あとは私が hugo のテーマとしてテンプレートの組み込めるかどうか次第。今週末には実家帰らないといけないし、毎日やることがいっぱいいっぱい。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0826/>簡単な現象の組み合わせ障害</a></h1><div class=post-meta><time class=post-date>2022-08-26 (Fri.) ::</time></div><span class=post-tags>#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;
#<a href=/diary/tags/datadog/>datadog</a>&nbsp;
#<a href=/diary/tags/operation/>operation</a>&nbsp;
#<a href=/diary/tags/drinking/>drinking</a>&nbsp;
#<a href=/diary/tags/tax/>tax</a>&nbsp;</span><div class=post-content><p>0時に寝て6時に起きた。</p><h2 id=eks-クラスター障害の原因判明>eks クラスター障害の原因判明</h2><p><a href=/diary/posts/2022/0820/#aws-インフラの調子が悪い>過去に2回発生していた eks クラスター障害</a> の原因がようやくわかった。テスト環境も本番環境は5日ごとに再現していて、datadog で k8s のダッシュボードでそれぞれの pod 単位のメモリ使用量をみると datadog-agent の pod がメモリリークしていることに気付いた。そこから当たりをつけて datadog-agent の issue を調べると次のバグに遭遇していた。</p><ul><li><a href=https://github.com/DataDog/datadog-agent/issues/12997>[BUG] agent leaves defunct processes with version 7.38.0 #12997</a></li></ul><p>ゾンビプロセスが生成されて、それが os のプロセス数上限に達してしまい、それによってプロセス (スレッド) が生成できなくなって、その結果として <a href=https://github.com/aws/amazon-vpc-cni-k8s>aws/amazon-vpc-cni-k8s</a> の <code>aws-node</code> という eks クラスターの管理アプリケーションが動かなくなって、それが動かないと k8s ノードのステータスが NotReady になってしまって、通常の pod のアプリケーションも動かなくなってしまうという現象が発生していた。datadog-agent のアップグレードは私が行ったものだし、その後の k8s ノードの監視や調査で気付きが足りなかったと反省した。</p><ul><li>datadog-agent の新しいバージョンをテスト環境でもうしばらく検証してもよかった</li><li>datadog-agent をリソースリークの可能性を私の中の調査対象から外していた<ul><li>世の中で使われているものに致命的なバグが起きないだろうという先入観があった</li></ul></li><li>プロセスを生成できない原因として考えられる背景を調査すべきだった<ul><li>ulimit を確認してリソース制限はないようにみえた</li><li>プロセス数やゾンビプロセスを調べていなかった</li><li>kernel に <code>/proc/sys/kernel/pid_max</code> という上限設定があることを知らなかった</li></ul></li><li>テスト環境と本番環境で5日程度で落ちるという周期性から気付くべきだった<ul><li>たしかにテスト環境から1日遅れて本番環境で障害が発生していた</li><li>周期性があることでリソースリークの可能性は高いとすぐに調査すべきだった</li></ul></li><li>datadog で k8s のダッシュボードを調べるべきだった<ul><li>すでに用意されているものがあったのでみようと思えばみえた</li></ul></li><li>aws のインフラ要因ではないかと疑っていた<ul><li>ごめんなさい</li></ul></li></ul><p>これは悔しい。自分の無能さや気付きの低さを実感した事件だった。私が注意深く観察していればもう1週間早く気付けた。そのせいで余分な障害と調査に時間を費やした。1つ1つは全く難しくない現象が巧妙に絡みあって隠蔽された結果としての状況に気付けなかった。注意して1つずつ観察して追跡していけばすぐに気付けた。本当に悔しい。</p><p>1つだけ言い訳をさせてもらうと、私は本番環境にアクセスできない。だからテスト環境と本番環境で発生している現象が同じかどうかを判断できず、調査を進める確証をもてなかった。</p><h2 id=呑み>呑み</h2><p>あまりに悔しかったのと調査してたら遅くなって晩ご飯食べる気力もなかったので気分転換に仲のよい焼き鳥屋さんに寄ってみた。あとから常連客のセブンイレブンの店長さんも来られて、私は初対面かなと思ってたんだけど先方は知っていると言ってたから以前にもカウンターでご一緒していたみたい。何気はなしに3人で2時前ぐらいまで雑談していた。</p><p>その店長さんがロレックスを購入しようと考えているという話しになって、資産または投資商品としてのロレックスの話しになった。たまたまヒカキンが1億円で買ったロレックスがいま2億円になっているといった話しがあったそうで、いまがバブルな状態らしいが、ロレックスをはじめとした高級時計の資産価値が上がっているらしい。私は腕時計を身につけないし高級時計もまったく興味はないが、投資商品の1つなんだというところに関心がもてた。</p><div class=video-container><iframe src=https://www.youtube.com/embed/1knsQZLeh7U allowfullscreen title=1億円で買った時計が大変なことになってしまいました…></iframe></div><p>中小企業の社長の一般的な節税方法の1つに外車を買ったり売ったりするという話しがある。儲かったときに経費で外車を買って、赤字のときに外車を売って雑所得に変える。車は社用車として経費で落とせるから可能なことだが、高級時計はどうなのだろうか？ 結論から言うと、普通の会社では高級時計は経費にできない。経費の原則は売上を上げるために必要な支出を経費とできる。普通の会社は高級時計で売上を上げることはできない。一方で経費として認められる職業もある。芸能人がそうだという。それは番組のために必要だという理屈で経費で落とせる。おそらくヒカキンも経費で高級時計を購入して、そのことを動画にしているのも仕事で必要だという言い訳作りの目的もあるのだと推測する。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0824/>vuejs の template 調査</a></h1><div class=post-meta><time class=post-date>2022-08-24 (Wed.) ::</time></div><span class=post-tags>#<a href=/diary/tags/operation/>operation</a>&nbsp;
#<a href=/diary/tags/vue.js/>vue.js</a>&nbsp;</span><div class=post-content><p>0時に寝て6時に起きた。</p><h2 id=連日のサービスイン作業>連日のサービスイン作業</h2><p>引き続きサービスインの運用対応は大変そうでちゃんと検証していない修正を慌ててマージしようとしているからテスト環境まで壊れてて関係ない開発にも影響が出ていた。今日も別の施設のサービスインだったらしくて、ある機能がないとそのサービスインの切り替え作業ができないという話しだったそうで、当日に慌てて pr を作ってマージしてた。先週からわかっていた必要な機能を実装してなくて、週末は残業も休出もしてなくて、今日になって慌てて修正してマージしてた。昔の開発と比べてがんばっててできないのではなくて、いまの開発はがんばってないからできないという雰囲気になったなという印象。</p><h2 id=vuejs-の-template-と-expression>vuejs の template と expression</h2><p>あるフォームのコンポーネントを作ろうと思って interface を定義していてデフォルト値をテンプレート側に指定できるといいんじゃないかと考えた。というのは typescript の interface のメンバーは値を保持できないから。例えば、次のようなコードで <code>:cols="item.col ?? 2"</code> のように表現できたら嬉しいように思う。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-xml data-lang=xml><span style=display:flex><span><span style=color:#f92672>&lt;v-row</span> <span style=color:#960050;background-color:#1e0010>dense</span> <span style=color:#a6e22e>v-for=</span><span style=color:#e6db74>&#34;item in conditions&#34;</span> <span style=color:#a6e22e>:key=</span><span style=color:#e6db74>&#34;item.label&#34;</span><span style=color:#f92672>&gt;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>&lt;v-col</span> <span style=color:#a6e22e>:cols=</span><span style=color:#e6db74>&#34;item.col ?? 2&#34;</span><span style=color:#f92672>&gt;</span>
</span></span><span style=display:flex><span>    {{ element }}
</span></span><span style=display:flex><span>  <span style=color:#f92672>&lt;/v-col&gt;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>&lt;/v-row&gt;</span>
</span></span></code></pre></div><p>余談だけど、<code>??</code> は null 合体演算子という名前は知っていたけど、これを英語で何と呼ぶのか知らなかった。<a href=https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Nullish_coalescing_operator>Nullish coalescing operator</a> と言う。ググってみると vuejs の issue でもそこそこ議論されていて vue3 からサポートするとしながら、根強い要望があるのか？ vue2 でも 2.7 でサポートしたらしい。こういうモダンな javascript の expression を ESNext syntax と呼んだりするみたい。それすらも知らなかった。</p><ul><li><a href=https://github.com/vuejs/vue/issues/11088>Optional chaining in templates does not seem to work #11088</a></li></ul><p>たまたまうちで使っているのは vue 2.6.14 なので vue 2.7 で動くのかどうか検証できないけど、いま使っている nuxtjs2 との依存関係があるのでそれ次第で vue 2.7 にアップグレードの可否が決まるらしい。全然フロントエンドの開発がわからないので、こういう基本的なところで引っかかると背景を調べるのに時間がかかる。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0822/>週明けのサービスイン</a></h1><div class=post-meta><time class=post-date>2022-08-22 (Mon.) ::</time></div><span class=post-tags>#<a href=/diary/tags/operation/>operation</a>&nbsp;</span><div class=post-content><p>0時に寝て7時に起きた。</p><h2 id=3つ目のサービスイン>3つ目のサービスイン</h2><p>またまた私は勘違いしていて明日だと思っていたら今日が3つ目のサービスインだった。<a href=/diary/posts/2022/0719/#2つ目のサービスイン>約1ヶ月ぶりのサービスイン</a> になる。もう3回目なので要領よく切り替え作業やるのかなと眺めてたけど、新たなトラブルもいくつかあって、これまで同様、ドタバタしているようにみえる。私は本番環境にアクセスできないので何かトラブルがあっても聞いた内容から類推で助言を述べるしかできず、とはいえ、何かあったら質問がくるかもしれないからハドルに入って成り行きを見守ってないといけない。とくに手伝うこともないのにメンバーの作業が完了するまで待ってないといけない。この切り替え作業や運用対応をやっていると要件定義やコードレビューなどは放置されるのでまた作業のスケジュールが先送りになる。私は別に困らないけど、しばらくだらだらした開発が続く。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0820/>休日の本番障害</a></h1><div class=post-meta><time class=post-date>2022-08-20 (Sat.) ::</time></div><span class=post-tags>#<a href=/diary/tags/life/>life</a>&nbsp;
#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;
#<a href=/diary/tags/operation/>operation</a>&nbsp;</span><div class=post-content><p>夕方から寝ていて何度か起きたものの、そのままずっと寝ていた。あまりないことなんだけど、珍しくたくさん眠れた。</p><h2 id=ストレッチ>ストレッチ</h2><p>今日の開脚幅は開始前160cmで、ストレッチ後163cmだった。計測の仕方がややいい加減だった気もしたが、先週より少しよくなったということにしておく。右腰の張りが強いのと肩が前に入りがちなので肩を開いて姿勢を保つように心がけるとよいとアドバイスをいただいた。もう通い始めて1年半ぐらい経つ。トレーナーさんも大半が入れ替わっていて通い始めたときに話しかけてくれた私が知っているトレーナーさんはほとんどいない。1年半も経つと人は変わっていくなというのを実感している。私の最初のトレーナーさんは社内制度で別の店舗の助っ人に行っているのでいなくなった人たちが辞めているわけでもないとは思うけど、1-2年で人が入れ替わってもサービスは継続していかないといけないし、会社ってそういうものだなと実感する機会でもある。</p><h2 id=aws-インフラの調子が悪い>aws インフラの調子が悪い？</h2><p>1-2週間ぐらい前からテスト環境を含めると複数回発生している <a href=/diary/posts/2022/0815/>eks クラスターの障害</a> がたまたま土曜日の夜という休日に発生した。いま eks クラスターのインフラの振る舞いを把握しているのは私だけなので、気付いてから指示を出して問題が発生している k8s ノードの削除 (ec2 インスタンスの削除) で復旧させるワークアラウンドで復旧させた。私は本番環境にアクセスできないので詳しい調査はできない。状況を正しく把握できてはいないけれど、k8s ノードが死んだり生き返ったりする不安定な状況に発生しているらしく、k8s ノードを削除して新規に作り直すと復旧することがわかっている。NotReady と Ready を繰り返したりしてアプリケーションの振る舞いが不安定になる。NotReady,SchedulingDisabled になれば、おそらく drain して k8s ノードが入れ替わってくれるのだけど、そうならない不安定な状況があるみたい。これ以上の調査は aws のサポートに問い合わせないとわからない。</p></div></article><div class=pagination><div class=pagination__buttons><a href=/diary/tags/operation/page/2/ class="button next"><span class=button__text>過去の日記</span>
<span class=button__icon>→</span></a></div></div></div></div><footer class=footer><div class=footer__inner><div class="copyright copyright--user"><span>© 2021 Tetsuya Morimoto</span>
<span>:: Theme made by <a href=https://twitter.com/panr>panr</a></span></div></div></footer><script type=text/javascript src=/diary/bundle.min.js></script></div></body></html>