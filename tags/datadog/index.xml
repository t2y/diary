<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>datadog on forest nook</title><link>/diary/tags/datadog/</link><description>Recent content in datadog on forest nook</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><copyright>© 2021 Tetsuya Morimoto</copyright><lastBuildDate>Tue, 17 May 2022 11:11:11 +0900</lastBuildDate><atom:icon>/diary/favicon.ico</atom:icon><icon>/diary/favicon.ico</icon><atom:link href="/diary/tags/datadog/index.xml" rel="self" type="application/rss+xml"/><item><title>datadog のログアーカイブ</title><link>/diary/posts/2022/0517/</link><pubDate>Tue, 17 May 2022 11:11:11 +0900</pubDate><guid>/diary/posts/2022/0517/</guid><description>1時に寝て5時半に起きた。
datadog のログアーカイブ datadog には Log Archives という機能があって、datadog 経由でログをどこかのストレージに永続化できる。datadog プラットフォーム上では設定した期間内のログしか検索できず、おそらく料金の予算にあわせて期間を設定して、それが過ぎたら消えていくのだと思う。aws なら s3 に datadog に連携されたログをパイプライン処理してそのまま永続化できる。そのための s3 バケットの作成、s3 バケットへの datadog からのアクセス権限ロールの設定、datadog の aws インテグレーションの設定などをした。ドキュメントを読みながら1日あれば設定できたので難しくはない。もう cdk の設定にも慣れた感じで必要な権限を cdk の Stack としてコードで管理できるようにした。保守もばっちり。永続化されるログは gzip 圧縮されて時系列に s3 に永続化されるみたい。</description><content>&lt;p>1時に寝て5時半に起きた。&lt;/p>
&lt;h2 id="datadog-のログアーカイブ">datadog のログアーカイブ&lt;/h2>
&lt;p>datadog には &lt;a href="https://docs.datadoghq.com/logs/log_configuration/archives/?tab=awss3">Log Archives&lt;/a> という機能があって、datadog 経由でログをどこかのストレージに永続化できる。datadog プラットフォーム上では設定した期間内のログしか検索できず、おそらく料金の予算にあわせて期間を設定して、それが過ぎたら消えていくのだと思う。aws なら s3 に datadog に連携されたログをパイプライン処理してそのまま永続化できる。そのための s3 バケットの作成、s3 バケットへの datadog からのアクセス権限ロールの設定、datadog の aws インテグレーションの設定などをした。ドキュメントを読みながら1日あれば設定できたので難しくはない。もう cdk の設定にも慣れた感じで必要な権限を cdk の Stack としてコードで管理できるようにした。保守もばっちり。永続化されるログは gzip 圧縮されて時系列に s3 に永続化されるみたい。&lt;/p></content></item><item><title>wiki のドキュメント整理</title><link>/diary/posts/2022/0201/</link><pubDate>Tue, 01 Feb 2022 07:28:46 +0900</pubDate><guid>/diary/posts/2022/0201/</guid><description>23時に寝て4時半に起きた。昨日の帰りに自転車でこけて胸を強打してひたすら痛い。起き上がるのも痛い。安静にしてた。
kubernetes のログ管理と datadog-agent のログ連携不具合 先日、datadog にログ連携されていない不具合 が発生していて、その1次調査を終えたことについて書いた。緊急対応としては datadog-agent を再起動することで改善することはわかっていたので、その後、kubernetes のログ管理と datadog-agent がどうやって kubernetes クラスター上で実行されているアプリケーションのログを収集しているかを調査していた。今日は wiki に調査してわかったことなどをまとめていた。
kubernetes クラスターはコンテナランタイムに docker を使っていて、アプリケーションの stdout/stderr を docker の logging driver にリダイレクトし、JSON Lines に設定された logging driver が kubernetes ノード上にログファイルとして出力する。datadog-agent は autodiscovery 機能で pod の情報を常にポーリングしていて、pod が新たにデプロイされたらログファイルを pod 内にマウントして、そのマウントしたログファイルを読み込んでログ収集していると思われる。datadog-agent から pod の情報を取得するには kubernetes のサービスアカウントを使っていて、その credential が projected volume としてマウントされて pod 内から利用できる。その credential を使って kubelet api にリクエストすることで pod の情報を取得している。
文章で書けばたったこれだけのことなんだけど、たったこれだけのことを理解するのに次のドキュメントを読んだ。実際の調査のときはわからなかったのでもっと多くのドキュメントを読んでいる。いま書いたことを理解するならこのドキュメントを読めば理解できるはず。
https://kubernetes.io/docs/concepts/overview/components/ https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/ https://kubernetes.io/docs/concepts/cluster-administration/logging/ https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/ https://kubernetes.io/docs/concepts/storage/projected-volumes/ https://docs.datadoghq.com/agent/kubernetes/log/?tab=helm https://docs.datadoghq.com/getting_started/agent/autodiscovery/?tab=kubernetes ドキュメントに書いてあることを深く理解するために、kubernetes と datadog-agent のソースコードも読んだ。どちらも go 言語で実装されている。</description><content>&lt;p>23時に寝て4時半に起きた。昨日の帰りに自転車でこけて胸を強打してひたすら痛い。起き上がるのも痛い。安静にしてた。&lt;/p>
&lt;h2 id="kubernetes-のログ管理と-datadog-agent-のログ連携不具合">kubernetes のログ管理と datadog-agent のログ連携不具合&lt;/h2>
&lt;p>先日、&lt;a href="/diary/diary/posts/2022/0127/#ログ連携の不具合調査">datadog にログ連携されていない不具合&lt;/a> が発生していて、その1次調査を終えたことについて書いた。緊急対応としては datadog-agent を再起動することで改善することはわかっていたので、その後、kubernetes のログ管理と datadog-agent がどうやって kubernetes クラスター上で実行されているアプリケーションのログを収集しているかを調査していた。今日は wiki に調査してわかったことなどをまとめていた。&lt;/p>
&lt;p>kubernetes クラスターはコンテナランタイムに docker を使っていて、アプリケーションの stdout/stderr を docker の logging driver にリダイレクトし、JSON Lines に設定された logging driver が kubernetes ノード上にログファイルとして出力する。datadog-agent は autodiscovery 機能で pod の情報を常にポーリングしていて、pod が新たにデプロイされたらログファイルを pod 内にマウントして、そのマウントしたログファイルを読み込んでログ収集していると思われる。datadog-agent から pod の情報を取得するには kubernetes のサービスアカウントを使っていて、その credential が projected volume としてマウントされて pod 内から利用できる。その credential を使って kubelet api にリクエストすることで pod の情報を取得している。&lt;/p>
&lt;p>文章で書けばたったこれだけのことなんだけど、たったこれだけのことを理解するのに次のドキュメントを読んだ。実際の調査のときはわからなかったのでもっと多くのドキュメントを読んでいる。いま書いたことを理解するならこのドキュメントを読めば理解できるはず。&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/overview/components/">https://kubernetes.io/docs/concepts/overview/components/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/">https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/">https://kubernetes.io/docs/concepts/cluster-administration/logging/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/">https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://kubernetes.io/docs/concepts/storage/projected-volumes/">https://kubernetes.io/docs/concepts/storage/projected-volumes/&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.datadoghq.com/agent/kubernetes/log/?tab=helm">https://docs.datadoghq.com/agent/kubernetes/log/?tab=helm&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.datadoghq.com/getting_started/agent/autodiscovery/?tab=kubernetes">https://docs.datadoghq.com/getting_started/agent/autodiscovery/?tab=kubernetes&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>ドキュメントに書いてあることを深く理解するために、kubernetes と datadog-agent のソースコードも読んだ。どちらも go 言語で実装されている。&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/kubernetes/kubernetes">https://github.com/kubernetes/kubernetes&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/DataDog/datadog-agent">https://github.com/DataDog/datadog-agent&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;code>kubectl logs&lt;/code> の振る舞いを確認するだけでも、ソースコードからは実際のログファイルを open してストリームを返しているところはわからなかった。api 呼び出しが連携されて抽象化されていて、コンポーネントの役割分担があって、何も知らずにコードを読んでいてもわからなかった。Kubernetes の低レイヤーのところは Container Runtime Interface (CRI) という標準化を行い、1.20 から docker は非推奨となり、将来的に CRI を提供する実装に置き換わるらしい。ログファイルを open する役割は CRI の実装が担うんじゃないかと思うけど、そこまでは調べきれなかった。また機会があれば CRI の実装も読んでみる。&lt;/p>
&lt;figure>&lt;img src="/diary/diary/img/2022/0201_kubectl-logs.png"/>
&lt;/figure></content></item><item><title>datadog-agent のログ連携の不具合調査</title><link>/diary/posts/2022/0127/</link><pubDate>Thu, 27 Jan 2022 07:47:57 +0900</pubDate><guid>/diary/posts/2022/0127/</guid><description>0時に寝て4時に起きた。朝から1時間ほどドラクエタクトやってた。
ログ連携の不具合調査 少し前に本番環境で datadog-agent からログが (クラウドの) datadog に連携されていないことがわかった。kubectl logs のコマンドで確認すると、アプリケーションのログは出力されているので datadog-agent から datadog にログを送信するところの問題であるように推測された。たまたま今日、同じような現象をテスト環境で確認できた。ちょうどスクラムのプランニングでログ調査のための作業をするチケットの承認を得たところだった。満を持して発生したような障害だったので私が調査すると明言して調査してた。半日ぐらい調査して、pod 内の credential 情報が置き換わってしまうことが原因っぽいと特定できたが、なぜ置き換わってしまうのかはまだわからない。もう少し調査して解決したら会社のテックブログにいいなと思ったので、日記に書いてた内容を移行することにした。</description><content>&lt;p>0時に寝て4時に起きた。朝から1時間ほどドラクエタクトやってた。&lt;/p>
&lt;h2 id="ログ連携の不具合調査">ログ連携の不具合調査&lt;/h2>
&lt;p>少し前に本番環境で &lt;a href="https://github.com/DataDog/datadog-agent">datadog-agent&lt;/a> からログが (クラウドの) datadog に連携されていないことがわかった。kubectl logs のコマンドで確認すると、アプリケーションのログは出力されているので datadog-agent から datadog にログを送信するところの問題であるように推測された。たまたま今日、同じような現象をテスト環境で確認できた。ちょうどスクラムのプランニングでログ調査のための作業をするチケットの承認を得たところだった。満を持して発生したような障害だったので私が調査すると明言して調査してた。半日ぐらい調査して、pod 内の credential 情報が置き換わってしまうことが原因っぽいと特定できたが、なぜ置き換わってしまうのかはまだわからない。もう少し調査して解決したら会社のテックブログにいいなと思ったので、日記に書いてた内容を移行することにした。&lt;/p></content></item><item><title>datadog のログ管理</title><link>/diary/posts/2022/0105/</link><pubDate>Wed, 05 Jan 2022 07:41:18 +0900</pubDate><guid>/diary/posts/2022/0105/</guid><description>0時に寝て5時に起きた。昨日は早く寝たので早く起きた。
ふりかえり お仕事でのスクラムのふりかえり。課題管理システムの一本化 や slack のマルチチャンネルゲスト移行 について、メンバーのよかったコメントがいくつか出た。私は経験者なので、これらの結果がどうなるかは最初からわかっていて、移行中に運用面からもあれこれプラクティスを提案しながら結果が出やすいようにサポートしていた。まだまだもっとうまく運用できるけれど、経験則では、他のメンバーの運用がついてくるには半年ぐらいかかるだろう。仕組みを取り入れただけではまだ効果が半分で、適切な運用を継続することでさらにその効果を実感できるようになる。これからも注力していく。
ともあれ、私がお手伝い始めた初日から非効率だと考えていた3大課題のうちの2つは2ヶ月経って対応された。ついでに書いておくと、最後の1つはカレンダー共有の課題がある。お手伝い先の社内で使っているカレンダーを協力会社のメンバーはみることができない。その逆も然り。したがって、正社員と協力会社でカレンダーを共有できない。これがスケジュール調整コストやコミュニケーションコストを高くしている。カレンダーを共有していると、例えば、slack でメンションして予定が入っていないならすぐに返信がくることを期待するけど、会議中だったらその会議が終わってからかな？といった予測が働く。仮に会議が3つ連続していれば、PR のレビューはすぐできないだろうと推測される。プロジェクトメンバーでカレンダーを共有できないと、相手の行動予測の精度が下がり、結果としてコミュニケーションコストが高くつく。
生産性をあげるには特別なことをやらなくても、当たり前のことを当たり前にしていくだけでも効果がある。同じ職場でずっと働いていると、当たり前じゃないことがわからなくなってしまって非効率になってしまうことも多々ある。そういうところは外部の人間が指摘することで改善できる余地となる。
datadog のログ管理 お仕事で datadog の ログ管理 機能を調べている。メトリクスしか使ったことがなかったけど、ログ管理も一通りの機能は揃っていていろいろできる。なぜか私が手伝う会社は datadog を使っていて、他のサービスも試してみたいという気持ちもあるんだけど、やっぱり datadog は優れたサービスということなのだろうか。</description><content>&lt;p>0時に寝て5時に起きた。昨日は早く寝たので早く起きた。&lt;/p>
&lt;h2 id="ふりかえり">ふりかえり&lt;/h2>
&lt;p>お仕事でのスクラムのふりかえり。&lt;a href="/diary/diary/posts/2021/1222/#課題管理システムを一本化する">課題管理システムの一本化&lt;/a> や &lt;a href="/diary/diary/posts/2021/1224/#slack-のマルチチャンネルゲスト">slack のマルチチャンネルゲスト移行&lt;/a> について、メンバーのよかったコメントがいくつか出た。私は経験者なので、これらの結果がどうなるかは最初からわかっていて、移行中に運用面からもあれこれプラクティスを提案しながら結果が出やすいようにサポートしていた。まだまだもっとうまく運用できるけれど、経験則では、他のメンバーの運用がついてくるには半年ぐらいかかるだろう。仕組みを取り入れただけではまだ効果が半分で、適切な運用を継続することでさらにその効果を実感できるようになる。これからも注力していく。&lt;/p>
&lt;p>ともあれ、私がお手伝い始めた初日から非効率だと考えていた3大課題のうちの2つは2ヶ月経って対応された。ついでに書いておくと、最後の1つはカレンダー共有の課題がある。お手伝い先の社内で使っているカレンダーを協力会社のメンバーはみることができない。その逆も然り。したがって、正社員と協力会社でカレンダーを共有できない。これがスケジュール調整コストやコミュニケーションコストを高くしている。カレンダーを共有していると、例えば、slack でメンションして予定が入っていないならすぐに返信がくることを期待するけど、会議中だったらその会議が終わってからかな？といった予測が働く。仮に会議が3つ連続していれば、PR のレビューはすぐできないだろうと推測される。プロジェクトメンバーでカレンダーを共有できないと、相手の行動予測の精度が下がり、結果としてコミュニケーションコストが高くつく。&lt;/p>
&lt;p>生産性をあげるには特別なことをやらなくても、当たり前のことを当たり前にしていくだけでも効果がある。同じ職場でずっと働いていると、当たり前じゃないことがわからなくなってしまって非効率になってしまうことも多々ある。そういうところは外部の人間が指摘することで改善できる余地となる。&lt;/p>
&lt;h2 id="datadog-のログ管理">datadog のログ管理&lt;/h2>
&lt;p>お仕事で datadog の &lt;a href="https://docs.datadoghq.com/ja/logs/">ログ管理&lt;/a> 機能を調べている。メトリクスしか使ったことがなかったけど、ログ管理も一通りの機能は揃っていていろいろできる。なぜか私が手伝う会社は datadog を使っていて、他のサービスも試してみたいという気持ちもあるんだけど、やっぱり datadog は優れたサービスということなのだろうか。&lt;/p></content></item></channel></rss>