<!doctype html><html lang=en><head><title>Kubernetes :: forest nook</title>
<meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=keywords content><meta name=robots content="noodp"><link rel=canonical href=/diary/tags/kubernetes/><link rel=stylesheet href=/diary/styles.css><link rel=stylesheet href=/diary/style.css><link rel="shortcut icon" href=/diary/favicon.ico><meta name=twitter:card content="summary"><meta name=twitter:site content="t2y"><meta name=twitter:creator content><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:title" content="Kubernetes"><meta property="og:description" content><meta property="og:url" content="/diary/tags/kubernetes/"><meta property="og:site_name" content="forest nook"><meta property="og:image" content="/diary/favicon.ico"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="627"><link href=/diary/tags/kubernetes/index.xml rel=alternate type=application/rss+xml title="forest nook"></head><body class=green><div class="container full headings--one-size"><header class=header><div class=header__inner><div class=header__logo><a href=/diary><div class=logo>forest nook</div></a></div><ul class="menu menu--mobile"><li class=menu__trigger>Menu&nbsp;▾</li><li><ul class=menu__dropdown><li><a href=/diary/about>自己紹介</a></li><li><a href=/diary/dates>月別一覧</a></li><li><a href=/diary/tags>タグ一覧</a></li></ul></li></ul></div><nav class=navigation-menu><ul class="navigation-menu__inner menu--desktop"><li><a href=/diary/about>自己紹介</a></li><li><a href=/diary/dates>月別一覧</a></li><li><a href=/diary/tags>タグ一覧</a></li></ul></nav></header><div class=content><h1>Posts for: #Kubernetes</h1><div class=posts><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2023/0114/>ストレッチと読書会で体力を使い果たした</a></h1><div class=post-meta><time class=post-date>2023-01-14</time></div><span class=post-tags>#<a href=/diary/tags/life/>life</a>&nbsp;
#<a href=/diary/tags/event/>event</a>&nbsp;
#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;</span><div class=post-content><p>23時に寝て3時と5時に起きつつ7時に起きた。21時半には出張から家に戻ってきて天気がよかったらオフィスへ行ってたんだけど、雨降りだったのでそのまま寝てた。今日もストレッチを終えてから読書会に参加したらその後は眠くなってしまって家に帰って寝ていた。ストレッチと読書会しかやっていないのに一日の体力を使い果たした状態になるぐらいの疲労が蓄積している。</p><h2 id=ストレッチ>ストレッチ</h2><p>今日の開脚幅は開始前155cmで、ストレッチ後159cmだった。数字の上では先週と大差ないのだけど、疲労の蓄積で右腰と右股関節周りが大変なことになっている。久しぶりにストレッチを受けていて辛くて耐えきれないところの一歩手前まで到達していた。ふくらはぎとか限界に近かったが、なんとか耐えきった。出張前に懸念していたことでもあったけれど、結果として、出張前のストレッチで復調しつつあった体調は悪化したと言わざるを得ない。たくさん歩いたことや慣れないホテル暮らしで腰と右足に負担がかかってしまった。</p><h2 id=オンライン読書会>オンライン読書会</h2><p>先月はオフィスの引っ越しで不参加だったため、1ヶ月飛ばしで <a href=https://technical-book-reading-2.connpass.com/event/268668/>第6回『Go言語による分散サービス』オンライン読書会</a> に参加した。本書の読書会は今日で最後の読書会で次の2章を読んだ。</p><ul><li>10章 Kubernetes でローカルにアプリケーションをデプロイ</li><li>11章 アプリケーションを Kubernetes でクラウドにデプロイ</li></ul><p>10章では <a href=https://kind.sigs.k8s.io/>kind</a> というローカル k8s クラスターを構築するツールを使って go アプリケーションをデプロイする。データベースのようなデータを永続化するようなサービスのためのリソース種別に <a href=https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/>StatefulSets</a> がある。私は使ったことがないリソース種別だったのでキーワードを知ることができてよかった。<a href=https://jsonnet.org/>jsonnet</a> というデータテンプレート言語というツールも出てきて、なんだこれは？と思ってびっくりした。これも初見だし、使っている話しも聞いたことなかった。本書でも k8s については書籍を一冊書いても足りないと説明されていて、アプリケーションのデプロイに必要な k8s マニフェストの説明を10章だけでやって、ほとんどの読者は置いてけぼりだと思う。k8s の運用経験のある私が読んでも yaml の正当性なんて動かしてみないとわからないし、k8s はバージョンアップが速いのですぐに陳腐化する可能性もある。helm のパッケージングなどにも触れていてキーワードを知るという意味ではよかったと思う。この2つの章は k8s へのデプロイはこんな感じですよという雰囲気を味わってもらうお気持ち程度の内容だと思う。</p><p>15時頃には読み終えて、それから8人ぐらいで雑談していた。私は書籍の組版を自分でやったことはないのだけど、しばたさんは出版社によっては自分で組版までやって pdf で納品しているらしい。現行は tex で管理しているようにみえる。余白の調整や索引作るのも自分でやっているらしい。ある本は後になってから出版社の規定している余白よりも広過ぎてページ数が増えたことに気付いて、その後の本で余白を調整したりしたとのこと。本来はそういうお仕事は編集者のお仕事ではある。とくに索引は数ページになったりするので大変といった話しをされていた。effective java 第3版だと索引だけで9ページある。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/1109/>軽量のコンテナオーケストレーションツールは存在しない</a></h1><div class=post-meta><time class=post-date>2022-11-09</time></div><span class=post-tags>#<a href=/diary/tags/docker/>docker</a>&nbsp;
#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;
#<a href=/diary/tags/event/>event</a>&nbsp;</span><div class=post-content><p>0時に寝て6時に起きた。冷蔵庫に飲みものなくて不安。</p><h2 id=docker-の-swarm-mode>docker の swarm mode</h2><p>昨日から docker の <a href=https://docs.docker.com/engine/swarm/>swarm mode</a> について調べていた。</p><p>オンプレにコンテナのアプリケーションをデプロイするにあたり、軽量のコンテナオーケストレーションツールはないかと調べ始めた。<a href=https://www.portainer.io/blog/orchestrator-wars-continue>Kubernetes vs Docker Swarm vs Nomad - the orchestrator wars continue?</a> を記事を読むと、軽量のオーケストレーションツールと言えるのは swarm mode か <a href=https://www.nomadproject.io/>Nomad</a> ぐらいしかない。docker に付属しているならまずはそれを調べるべきだろうと調査した。そして swarm mode の採用は見送った。現時点でこの機能が廃止されるというアナウンスはないが、あまり保守されておらず、docker 社も積極的に推進していない。近い将来、機能が廃止される可能性が高いと私は判断した。</p><p>docker のドキュメントをみながら3台の ec2 インスタンスでクラスターを構築してみて簡単であることは間違いない。コマンド2つで swarm クラスターを構築できる。一通り触ってみて数台のマシンを管理する軽量のコンテナオーケストレーションツールとしては十分だと私は思うけれど、残念ながらこのツールが求められる業務やビジネスは少ないのだろうと思う。みんな k8s に持ってかれたという感じかな。調べていて読んだ記事など。</p><ul><li><a href=https://dockerswarm.rocks/>Docker Swarm Rocks</a></li><li><a href=https://levelup.gitconnected.com/six-tips-for-running-swarm-cluster-in-production-e0f2ef367694>Six Tips For Running Swarm Cluster in Production</a></li><li><a href=https://www.reddit.com/r/docker/comments/936924/docker_swarm_in_production_anyone_using_it/>Docker swarm in production - Anyone using it?</a></li></ul><h2 id=hannali-dao-雑談>hannali dao 雑談</h2><p><a href=https://hannari-python.connpass.com/event/265098/>Hannali DAO #02</a> に参加した。</p><p>最初は dao とは何かをみんなで雑談してた。私はお仕事しながら軽く聞いているつもりだったのが、議論に口出しして熱中してた。技術的に私が理解できないことが出てくると、私の認識が誤っていたり新しい気付きがあったりする可能性があるので、ついつい詳細を聞いてみたくなる。hannali dao でトークンをばら撒く戦略をみんなで考えていて dao の宣伝をしたら貢献の1つとみなしてトークンをもらえる。私は twitter でいくつか hannali dao のツィートをしていて、1ツィートが 300 PROG とかで、合計で 1250 PROG のトークンをもらった。PROG というのは hannali dao でのみ使えるトークンね。</p><p>その後、ウォレットに名前を付けられる <a href=https://ens.domains/ja/>ENS (Ethereum Name Service)</a> というサービスがあるのを教えてもらった。ちょうどいくらか ethereum をもってたので metamask に送金して、metamask で ens の登録 (購入) をやってみた。初めて ethereum を使ってサービスの支払いをやってみた。これで私も web3 を完全に理解したよ。ens で名前を登録 (購入) するのに $22.58 、ドメイン名みたいなものでサブドメインも登録できる。サブドメインを付けるのに $2.96 かかり、その ens を metamask に紐付けるのに $7.49 がかかった。metamask に紐付けると <a href=https://etherscan.io/>https://etherscan.io/</a> などで検索したときにウォレットのアドレスではなく、ens で購入した名前が表示されるようになる。トランザクションの履歴に名前が付いてそれが誰なのかが他人にもわかってしまうことがどういった影響を及ぼすのか、プライバシー云々の他に私はまだわかっていない。web3 なので購入した名前は一般公開されているものだけど、その名前は知り合いにしかまだ教えていない。暗号資産のウォレットに名前を付けることの意味や体験などをこれから経験してみる。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0826/>簡単な現象の組み合わせ障害</a></h1><div class=post-meta><time class=post-date>2022-08-26</time></div><span class=post-tags>#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;
#<a href=/diary/tags/datadog/>datadog</a>&nbsp;
#<a href=/diary/tags/operation/>operation</a>&nbsp;
#<a href=/diary/tags/drinking/>drinking</a>&nbsp;
#<a href=/diary/tags/tax/>tax</a>&nbsp;</span><div class=post-content><p>0時に寝て6時に起きた。</p><h2 id=eks-クラスター障害の原因判明>eks クラスター障害の原因判明</h2><p><a href=/diary/posts/2022/0820/#aws-インフラの調子が悪い>過去に2回発生していた eks クラスター障害</a> の原因がようやくわかった。テスト環境も本番環境は5日ごとに再現していて、datadog で k8s のダッシュボードでそれぞれの pod 単位のメモリ使用量をみると datadog-agent の pod がメモリリークしていることに気付いた。そこから当たりをつけて datadog-agent の issue を調べると次のバグに遭遇していた。</p><ul><li><a href=https://github.com/DataDog/datadog-agent/issues/12997>[BUG] agent leaves defunct processes with version 7.38.0 #12997</a></li></ul><p>ゾンビプロセスが生成されて、それが os のプロセス数上限に達してしまい、それによってプロセス (スレッド) が生成できなくなって、その結果として <a href=https://github.com/aws/amazon-vpc-cni-k8s>aws/amazon-vpc-cni-k8s</a> の <code>aws-node</code> という eks クラスターの管理アプリケーションが動かなくなって、それが動かないと k8s ノードのステータスが NotReady になってしまって、通常の pod のアプリケーションも動かなくなってしまうという現象が発生していた。datadog-agent のアップグレードは私が行ったものだし、その後の k8s ノードの監視や調査で気付きが足りなかったと反省した。</p><ul><li>datadog-agent の新しいバージョンをテスト環境でもうしばらく検証してもよかった</li><li>datadog-agent をリソースリークの可能性を私の中の調査対象から外していた<ul><li>世の中で使われているものに致命的なバグが起きないだろうという先入観があった</li></ul></li><li>プロセスを生成できない原因として考えられる背景を調査すべきだった<ul><li>ulimit を確認してリソース制限はないようにみえた</li><li>プロセス数やゾンビプロセスを調べていなかった</li><li>kernel に <code>/proc/sys/kernel/pid_max</code> という上限設定があることを知らなかった</li></ul></li><li>テスト環境と本番環境で5日程度で落ちるという周期性から気付くべきだった<ul><li>たしかにテスト環境から1日遅れて本番環境で障害が発生していた</li><li>周期性があることでリソースリークの可能性は高いとすぐに調査すべきだった</li></ul></li><li>datadog で k8s のダッシュボードを調べるべきだった<ul><li>すでに用意されているものがあったのでみようと思えばみえた</li></ul></li><li>aws のインフラ要因ではないかと疑っていた<ul><li>ごめんなさい</li></ul></li></ul><p>これは悔しい。自分の無能さや気付きの低さを実感した事件だった。私が注意深く観察していればもう1週間早く気付けた。そのせいで余分な障害と調査に時間を費やした。1つ1つは全く難しくない現象が巧妙に絡みあって隠蔽された結果としての状況に気付けなかった。注意して1つずつ観察して追跡していけばすぐに気付けた。本当に悔しい。</p><p>1つだけ言い訳をさせてもらうと、私は本番環境にアクセスできない。だからテスト環境と本番環境で発生している現象が同じかどうかを判断できず、調査を進める確証をもてなかった。</p><h2 id=呑み>呑み</h2><p>あまりに悔しかったのと調査してたら遅くなって晩ご飯食べる気力もなかったので気分転換に仲のよい焼き鳥屋さんに寄ってみた。あとから常連客のセブンイレブンの店長さんも来られて、私は初対面かなと思ってたんだけど先方は知っていると言ってたから以前にもカウンターでご一緒していたみたい。何気はなしに3人で2時前ぐらいまで雑談していた。</p><p>その店長さんがロレックスを購入しようと考えているという話しになって、資産または投資商品としてのロレックスの話しになった。たまたまヒカキンが1億円で買ったロレックスがいま2億円になっているといった話しがあったそうで、いまがバブルな状態らしいが、ロレックスをはじめとした高級時計の資産価値が上がっているらしい。私は腕時計を身につけないし高級時計もまったく興味はないが、投資商品の1つなんだというところに関心がもてた。</p><div class=video-container><iframe src=https://www.youtube.com/embed/1knsQZLeh7U allowfullscreen title=1億円で買った時計が大変なことになってしまいました…></iframe></div><p>中小企業の社長の一般的な節税方法の1つに外車を買ったり売ったりするという話しがある。儲かったときに経費で外車を買って、赤字のときに外車を売って雑所得に変える。車は社用車として経費で落とせるから可能なことだが、高級時計はどうなのだろうか？ 結論から言うと、普通の会社では高級時計は経費にできない。経費の原則は売上を上げるために必要な支出を経費とできる。普通の会社は高級時計で売上を上げることはできない。一方で経費として認められる職業もある。芸能人がそうだという。それは番組のために必要だという理屈で経費で落とせる。おそらくヒカキンも経費で高級時計を購入して、そのことを動画にしているのも仕事で必要だという言い訳作りの目的もあるのだと推測する。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0820/>休日の本番障害</a></h1><div class=post-meta><time class=post-date>2022-08-20</time></div><span class=post-tags>#<a href=/diary/tags/life/>life</a>&nbsp;
#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;
#<a href=/diary/tags/operation/>operation</a>&nbsp;</span><div class=post-content><p>夕方から寝ていて何度か起きたものの、そのままずっと寝ていた。あまりないことなんだけど、珍しくたくさん眠れた。</p><h2 id=ストレッチ>ストレッチ</h2><p>今日の開脚幅は開始前160cmで、ストレッチ後163cmだった。計測の仕方がややいい加減だった気もしたが、先週より少しよくなったということにしておく。右腰の張りが強いのと肩が前に入りがちなので肩を開いて姿勢を保つように心がけるとよいとアドバイスをいただいた。もう通い始めて1年半ぐらい経つ。トレーナーさんも大半が入れ替わっていて通い始めたときに話しかけてくれた私が知っているトレーナーさんはほとんどいない。1年半も経つと人は変わっていくなというのを実感している。私の最初のトレーナーさんは社内制度で別の店舗の助っ人に行っているのでいなくなった人たちが辞めているわけでもないとは思うけど、1-2年で人が入れ替わってもサービスは継続していかないといけないし、会社ってそういうものだなと実感する機会でもある。</p><h2 id=aws-インフラの調子が悪い>aws インフラの調子が悪い？</h2><p>1-2週間ぐらい前からテスト環境を含めると複数回発生している <a href=/diary/posts/2022/0815/>eks クラスターの障害</a> がたまたま土曜日の夜という休日に発生した。いま eks クラスターのインフラの振る舞いを把握しているのは私だけなので、気付いてから指示を出して問題が発生している k8s ノードの削除 (ec2 インスタンスの削除) で復旧させるワークアラウンドで復旧させた。私は本番環境にアクセスできないので詳しい調査はできない。状況を正しく把握できてはいないけれど、k8s ノードが死んだり生き返ったりする不安定な状況に発生しているらしく、k8s ノードを削除して新規に作り直すと復旧することがわかっている。NotReady と Ready を繰り返したりしてアプリケーションの振る舞いが不安定になる。NotReady,SchedulingDisabled になれば、おそらく drain して k8s ノードが入れ替わってくれるのだけど、そうならない不安定な状況があるみたい。これ以上の調査は aws のサポートに問い合わせないとわからない。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0815/>k8s ノードの削除方法がわからない</a></h1><div class=post-meta><time class=post-date>2022-08-15</time></div><span class=post-tags>#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;
#<a href=/diary/tags/operation/>operation</a>&nbsp;</span><div class=post-content><p>1時に寝て7時に起きた。寝冷えしてお腹痛い。</p><h2 id=eks-クラスターの障害>eks クラスターの障害</h2><p>日曜日にテスト環境の eks クラスターで障害が発生していた。k8s ノードが NotReady になっていて、しばらくすると NotReady,SchedulingDisabled に変わって、それから新しい k8s ノードが起動して古いものが削除されて置き換わった。おそらくエラーが発生し始めてから1時間ほどはかかっていたと思う。わりと時間がかかるので明らかに k8s ノードが不調だと人間が判断しているなら ec2 インスタンスの切り替えを早くやりたい。k8s の公式ドキュメントの <a href=https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/#use-kubectl-drain-to-remove-a-node-from-service>Use kubectl drain to remove a node from service</a> では次の手順で行うように書いてある。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl drain &lt;node name&gt;
</span></span></code></pre></div><p>drain が正常終了すれば安全に k8s ノードを削除してよいのかな？</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl delete node &lt;node name&gt;
</span></span></code></pre></div><p>eks クラスターで障害が発生していたときに drain を実行するとエラーになったのでそのまま delete node したら k8s ノードは削除されたものの、自動的に新しい k8s ノードが起動しなかった。aws のマネジメントコンソールから ec2 インスタンスを調べたら起動したままだったので強制的に ec2 インスタンスを終了させたところ、オートスケールの設定から ec2 インスタンスが起動してきて復旧した。但し、このやり方は k8s が意図した手順ではないようにも思える。軽く調べた範囲では k8s ノードの正しい削除方法 (置き換え方法？) がみつからなかった。そんなことを日曜日に確認していたら月曜日にほぼ同じ現象が本番環境の eks クラスターでも発生した。私は一度経験していたので同僚に指示して経過を観察していた。ここで書いたのと同じような手順で復旧した。おそらく aws 側のなにかのメンテナンス作業でうちの eks クラスターだと k8s ノードが死んでしまうような作業があったのではないか？と疑いをもっている。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0810/>アプリケーションとジョブの違いと一時停止</a></h1><div class=post-meta><time class=post-date>2022-08-10</time></div><span class=post-tags>#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;</span><div class=post-content><p>2時に寝て5時に起きた。たった3時間しか寝てないのに夜中に1回は起きている。スポットで9時から会議が入ったのでそれまでに朝のお仕事を終わらせようと思ったら早起きできた。6時前にはオフィスに行ってお仕事を始められた。</p><h2 id=アプリケーションからジョブへの移行>アプリケーションからジョブへの移行</h2><p>k8s の cronjob を活用する前は spring の <a href=https://www.baeldung.com/spring-scheduled-tasks>Scheduled</a> アノテーションで定期実行処理を書いていた。アプリケーションサーバー内の1スレッドが定期実行していた。これはスケールアウト前提のアプリケーションサーバーには向いてなくて、複数のアプリケーションサーバーをスケールアウトさせてデプロイすると、定期処理も複数実行されてしまい、同時実行できない類の処理だと問題になる。k8s の cronjob は同時実行しない設定などもあるため、k8s の cronjob へ移行している。</p><p>移行作業の準備をしていてアプリケーションサーバーの pod は <code>replicas</code> を調整することで一時停止の代替となるオペレーションができる。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl scale --replicas<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span> deployment/my-app
</span></span><span style=display:flex><span>deployment.apps/my-app scaled
</span></span></code></pre></div><p>移行時のアプリケーションサーバーはこれで無効にしておき、cronjob に入れ替えるといった切り戻し可能な状態で移行できる。cronjob も <code>suspend</code> のフラグを使うことで一時停止できるので検証しながら双方を切り替えることができる。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl patch cronjob my-batch-job1 -p <span style=color:#e6db74>&#39;{&#34;spec&#34;: {&#34;suspend&#34;: true}}}&#39;</span>
</span></span><span style=display:flex><span>cronjob.batch/my-batch-job1 patched
</span></span></code></pre></div></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0808/>k8s クラスターの service account とロール</a></h1><div class=post-meta><time class=post-date>2022-08-08</time></div><span class=post-tags>#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;</span><div class=post-content><p>23時に寝て6時に起きた。前日は夕方からだらだらしてた。</p><h2 id=k8s-クラスターの権限管理>k8s クラスターの権限管理</h2><p>初期のクラスターを私が構築したわけではないため、権限周りはあまりよくわかっていない。k8s には2つのユーザーアカウントがある。</p><ul><li>user account: 人向け</li><li>service account: アプリケーション向け</li></ul><blockquote><p>In this regard, Kubernetes does not have objects which represent normal user accounts. Normal users cannot be added to a cluster through an API call.</p><p><a href=https://kubernetes.io/docs/reference/access-authn-authz/authentication/#users-in-kubernetes>https://kubernetes.io/docs/reference/access-authn-authz/authentication/#users-in-kubernetes</a></p></blockquote><p>但し、ユーザーアカウントを表すオブジェクトはなく、api 経由でクラスターにユーザーを追加したりはできない。ユーザーは存在しないけど、認証はできる仕組みを私は知らないので関心がある。それはまた今度調べるとして、今回は service account の権限を変更した。service account は pod 内から k8s の api サーバーにアクセスするときの認証などに使われる。デフォルトの権限だと、api サーバーのエンドポイントへの書き込み権限がない (?) ようなので追加する。</p><blockquote><p>In order from most secure to least secure, the approaches are:</p><ol><li>Grant a role to an application-specific service account (best practice)</li><li>Grant a role to the &ldquo;default&rdquo; service account in a namespace</li><li>Grant a role to all service accounts in a namespace</li><li>Grant a limited role to all service accounts cluster-wide (discouraged)</li><li>Grant super-user access to all service accounts cluster-wide (strongly discouraged)</li></ol><p><a href=https://kubernetes.io/docs/reference/access-authn-authz/rbac/#service-account-permissions>ServiceAccount permissions</a></p></blockquote><p>セキュアな順番として上から自分たちの環境にあうかどうかを判断すればよい。私の場合、わざわざ新規に service account を作るほどの要件ではないため、2番目の <code>default</code> の service account にロールを与えることにした。<code>RoleBinding</code> というキーワードがあるので既存のクラスターロールから <code>edit</code> という権限を与える。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl create rolebinding default-edit-role --clusterrole<span style=color:#f92672>=</span>edit --serviceaccount<span style=color:#f92672>=</span>default:default --namespace default
</span></span><span style=display:flex><span>rolebinding.rbac.authorization.k8s.io/default-edit-role created
</span></span></code></pre></div><p>ここでは <code>default-edit-role</code> という RoleBinding を作成した。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get rolebinding default-edit-role -o yaml
</span></span><span style=display:flex><span>apiVersion: rbac.authorization.k8s.io/v1
</span></span><span style=display:flex><span>kind: RoleBinding
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  creationTimestamp: <span style=color:#e6db74>&#34;2022-08-08T08:27:12Z&#34;</span>
</span></span><span style=display:flex><span>  name: default-edit-role
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  resourceVersion: <span style=color:#e6db74>&#34;152660975&#34;</span>
</span></span><span style=display:flex><span>  uid: 6de13b71-3103-448c-805a-66e9400f61c3
</span></span><span style=display:flex><span>roleRef:
</span></span><span style=display:flex><span>  apiGroup: rbac.authorization.k8s.io
</span></span><span style=display:flex><span>  kind: ClusterRole
</span></span><span style=display:flex><span>  name: edit
</span></span><span style=display:flex><span>subjects:
</span></span><span style=display:flex><span>- kind: ServiceAccount
</span></span><span style=display:flex><span>  name: default
</span></span><span style=display:flex><span>  namespace: default
</span></span></code></pre></div><p>これで cronjob から job を作成する権限が付与された。<a href=https://kubernetes.io/docs/reference/access-authn-authz/rbac/#write-access-for-endpoints>Write access for Endpoints</a> によると、新規に作成した v1.22 以降のクラスターではエンドポイントに対する write アクセス権限が異なるように記載されている。一方で v1.22 にアップグレードしたクラスターは影響を受けないとも記述されている。私がいま運用しているクラスターは v1.21 から v1.22 にアップグレードしたクラスターなので <code>edit</code> ロールでうまくいったのかもしれない。クラスターのバージョンによって設定が異なるかもしれない。</p></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0807/>wiremock を使った kubernetes モックサーバーのテスト拡張</a></h1><div class=post-meta><time class=post-date>2022-08-07</time></div><span class=post-tags>#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;
#<a href=/diary/tags/java/>java</a>&nbsp;
#<a href=/diary/tags/testing/>testing</a>&nbsp;</span><div class=post-content><p>2時に寝て7時に起きて9時までだらだらしてた。</p><h2 id=kubernetes-clients-のライブラリ実装>Kubernetes Clients のライブラリ実装</h2><p><a href=/diary/posts/2022/0806/#kubernetes-clients-のサンプル実装>昨日の続き</a> 。ある程度、クライアントの振る舞いを確認できたので自前のライブラリを作ることにした。ライブラリなのでテストをちゃんと書きたいと思って単体テストのやり方を調べてたら Kubernetes Clients のリポジトリにも単体テストはほとんどなくて、どうも e2e テストの方を重視しているようにもみえた。github issues を検索してみたら次の issue をみつけた。</p><ul><li><a href=https://github.com/apache/submarine/issues/956>[DESIGN] Add k8s mock client and server test case #956</a></li></ul><p>なにかしら単体テストの仕組みを作った方がいいんじゃないかという提案と一緒に issue の作者？かどうかはわからんけど、<a href=https://wiremock.org/>wiremock</a> を使ったテストのサンプルコードをあげていた。名前だけは聞いたことがあったけど、過去に使ったこともなく、どういうものか全くわかってない。ドキュメントを軽く読んでみたら http モックサーバーらしい。issue の内容を参考にしながら wiremock のドキュメントをみて junit5 のテスト拡張を書いてみた。これが適切な実装かはあまり自信がないけど、こんな感じでモックサーバーとモッククライアントの junit5 のテスト拡張を実装した。これは static なモックサーバーの設定になるので wiremock 自体の起動コストは速く感じた。ライブラリのテストとしては申し分ない。いまのところは自画自賛。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:#a6e22e>@Documented</span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@Target</span>(ElementType.<span style=color:#a6e22e>FIELD</span>)
</span></span><span style=display:flex><span><span style=color:#a6e22e>@Retention</span>(RetentionPolicy.<span style=color:#a6e22e>RUNTIME</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>public</span> <span style=color:#a6e22e>@interface</span> KubernetesApiClient {
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:#66d9ef>public</span> <span style=color:#66d9ef>class</span> <span style=color:#a6e22e>SetupKubernetesWireMock</span> <span style=color:#66d9ef>implements</span> BeforeAllCallback, BeforeEachCallback, ExtensionContext.<span style=color:#a6e22e>Store</span>.<span style=color:#a6e22e>CloseableResource</span> {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>final</span> Logger logger <span style=color:#f92672>=</span> LogManager.<span style=color:#a6e22e>getLogger</span>(SetupKubernetesWireMock.<span style=color:#a6e22e>class</span>.<span style=color:#a6e22e>getName</span>());
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>int</span> PORT <span style=color:#f92672>=</span> 8384;
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>static</span> WireMockServer wireMockServer <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> WireMockServer(options().<span style=color:#a6e22e>port</span>(PORT));
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>static</span> <span style=color:#66d9ef>boolean</span> started <span style=color:#f92672>=</span> <span style=color:#66d9ef>false</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> ApiClient apiClient;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>@Override</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>beforeAll</span>(ExtensionContext context) <span style=color:#66d9ef>throws</span> Exception {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> (<span style=color:#f92672>!</span>started) {
</span></span><span style=display:flex><span>            wireMockServer.<span style=color:#a6e22e>start</span>();
</span></span><span style=display:flex><span>            started <span style=color:#f92672>=</span> <span style=color:#66d9ef>true</span>;
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>configureMockClient</span>();
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>var</span> basePath <span style=color:#f92672>=</span> String.<span style=color:#a6e22e>format</span>(<span style=color:#e6db74>&#34;http://localhost:%d&#34;</span>, wireMockServer.<span style=color:#a6e22e>port</span>());
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>apiClient</span> <span style=color:#f92672>=</span> ClientBuilder.<span style=color:#a6e22e>standard</span>().<span style=color:#a6e22e>setBasePath</span>(basePath).<span style=color:#a6e22e>build</span>();
</span></span><span style=display:flex><span>            logger.<span style=color:#a6e22e>info</span>(<span style=color:#e6db74>&#34;started kubernetes wiremock: {}&#34;</span>, basePath);
</span></span><span style=display:flex><span>            context.<span style=color:#a6e22e>getRoot</span>().<span style=color:#a6e22e>getStore</span>(GLOBAL).<span style=color:#a6e22e>put</span>(<span style=color:#e6db74>&#34;SetupKubernetesWireMock&#34;</span>, <span style=color:#66d9ef>this</span>);
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>@Override</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>beforeEach</span>(ExtensionContext context) <span style=color:#66d9ef>throws</span> Exception {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>var</span> instance : context.<span style=color:#a6e22e>getRequiredTestInstances</span>().<span style=color:#a6e22e>getAllInstances</span>()) {
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>var</span> field : instance.<span style=color:#a6e22e>getClass</span>().<span style=color:#a6e22e>getDeclaredFields</span>()) {
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> (field.<span style=color:#a6e22e>isAnnotationPresent</span>(KubernetesApiClient.<span style=color:#a6e22e>class</span>)) {
</span></span><span style=display:flex><span>                    field.<span style=color:#a6e22e>setAccessible</span>(<span style=color:#66d9ef>true</span>);
</span></span><span style=display:flex><span>                    field.<span style=color:#a6e22e>set</span>(instance, <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>apiClient</span>);
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>@Override</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>public</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>close</span>() <span style=color:#66d9ef>throws</span> Throwable {
</span></span><span style=display:flex><span>        wireMockServer.<span style=color:#a6e22e>stop</span>();
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>configureMockClient</span>() <span style=color:#66d9ef>throws</span> IOException {
</span></span><span style=display:flex><span>        <span style=color:#75715e>// add static stubs for mock client</span>
</span></span><span style=display:flex><span>        configureFor(<span style=color:#e6db74>&#34;localhost&#34;</span>, PORT);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>stubForBatchGetCronjobs</span>();
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>stubForBatchGetSingleCronJob</span>(<span style=color:#e6db74>&#34;my-job1&#34;</span>);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>stubForBatchGetSingleCronJob</span>(<span style=color:#e6db74>&#34;my-job2&#34;</span>);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>stubForBatchGetSingleCronJob</span>(<span style=color:#e6db74>&#34;my-job3&#34;</span>);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>stubForBatchPostJob</span>();
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>stubForBatchGetJob</span>();
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>byte</span><span style=color:#f92672>[]</span> <span style=color:#a6e22e>getContents</span>(String name) <span style=color:#66d9ef>throws</span> IOException {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> json <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> File(<span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>getClass</span>().<span style=color:#a6e22e>getResource</span>(name).<span style=color:#a6e22e>getPath</span>());
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> Files.<span style=color:#a6e22e>readAllBytes</span>(Paths.<span style=color:#a6e22e>get</span>(json.<span style=color:#a6e22e>getPath</span>()));
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>stubForBatchGetCronjobs</span>() <span style=color:#66d9ef>throws</span> IOException {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> contents <span style=color:#f92672>=</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>getContents</span>(<span style=color:#e6db74>&#34;/fixtures/kubernetes/batch/cronjobs.json&#34;</span>);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> path <span style=color:#f92672>=</span> urlPathEqualTo(<span style=color:#e6db74>&#34;/apis/batch/v1/namespaces/default/cronjobs&#34;</span>);
</span></span><span style=display:flex><span>        stubFor(get(path).<span style=color:#a6e22e>willReturn</span>(aResponse().<span style=color:#a6e22e>withStatus</span>(200).<span style=color:#a6e22e>withBody</span>(contents)));
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>stubForBatchGetSingleCronJob</span>(String jobName) <span style=color:#66d9ef>throws</span> IOException {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> contents <span style=color:#f92672>=</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>getContents</span>(String.<span style=color:#a6e22e>format</span>(<span style=color:#e6db74>&#34;/fixtures/kubernetes/batch/%s.json&#34;</span>, jobName));
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> url <span style=color:#f92672>=</span> String.<span style=color:#a6e22e>format</span>(<span style=color:#e6db74>&#34;/apis/batch/v1/namespaces/default/cronjobs/%s&#34;</span>, jobName);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> path <span style=color:#f92672>=</span> urlPathEqualTo(url);
</span></span><span style=display:flex><span>        stubFor(get(path).<span style=color:#a6e22e>willReturn</span>(aResponse().<span style=color:#a6e22e>withStatus</span>(200).<span style=color:#a6e22e>withBody</span>(contents)));
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>stubForBatchPostJob</span>() <span style=color:#66d9ef>throws</span> IOException {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;/fixtures/kubernetes/batch/post-my-job.json&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> contents <span style=color:#f92672>=</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>getContents</span>(name);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> url <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;/apis/batch/v1/namespaces/default/jobs&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> path <span style=color:#f92672>=</span> urlPathEqualTo(url);
</span></span><span style=display:flex><span>        stubFor(post(path).<span style=color:#a6e22e>willReturn</span>(aResponse().<span style=color:#a6e22e>withStatus</span>(200).<span style=color:#a6e22e>withBody</span>(contents)));
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>void</span> <span style=color:#a6e22e>stubForBatchGetJob</span>() <span style=color:#66d9ef>throws</span> IOException {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;/fixtures/kubernetes/batch/get-my-job.json&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> contents <span style=color:#f92672>=</span> <span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>getContents</span>(name);
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> url <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;/apis/batch/v1/namespaces/default/jobs/my-job&#34;</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>var</span> path <span style=color:#f92672>=</span> urlPathEqualTo(url);
</span></span><span style=display:flex><span>        stubFor(get(urlPathEqualTo(url)).<span style=color:#a6e22e>willReturn</span>(aResponse().<span style=color:#a6e22e>withStatus</span>(200).<span style=color:#a6e22e>withBody</span>(contents)));
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0806/>Kubernetes Clients のサンプル実装</a></h1><div class=post-meta><time class=post-date>2022-08-06</time></div><span class=post-tags>#<a href=/diary/tags/life/>life</a>&nbsp;
#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;</span><div class=post-content><p>23時に寝て7時半に起きた。夜中も2回ぐらい起きる。暑さでまいってきた。</p><h2 id=ストレッチ>ストレッチ</h2><p>今日の開脚幅は開始前159cmで、ストレッチ後162cmだった。数字は悪くない。いつもはストレッチを受けていると疲労しているところが伸びることで体が軽くなっていく感覚があるのだけど、今日は体全体がだるくてストレッチを受けていてもなんかしんどいなぁとだるさを感じていた。コロナに感染してないと思うけど、夏バテの状態をそのままストレッチにも持ち込んだような感覚があった。腰の張りや肩甲骨の硬さなどが少し気になったかな。トレーナーさんには立ったときの姿勢が少し前よりで重心のバランスがよくないといったアドバイスをされた。とくにどこが悪いというわけでもないのになんかしんどい。</p><h2 id=kubernetes-clients-のサンプル実装>Kubernetes Clients のサンプル実装</h2><p><a href=/diary/posts/2022/0804/>Kubernetes Clients の調査</a> の続き。java クライアントを使って minikube でいくつか動かしてみた。openapi で生成した rest api クライントが提供されている。デフォルト設定でも minikube で普通に動いたのでおそらく裏で <code>$HOME/.kube/config</code> をみたり <code>/var/run/secrets/kubernetes.io/serviceaccount/token</code> を読み込んで認証ヘッダーに設定してくれたりするのだと推測する。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:#66d9ef>public</span> ApiClient <span style=color:#a6e22e>getKubernetesClient</span>() <span style=color:#66d9ef>throws</span> IOException {
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>var</span> client <span style=color:#f92672>=</span> Config.<span style=color:#a6e22e>defaultClient</span>();
</span></span><span style=display:flex><span>    io.<span style=color:#a6e22e>kubernetes</span>.<span style=color:#a6e22e>client</span>.<span style=color:#a6e22e>openapi</span>.<span style=color:#a6e22e>Configuration</span>.<span style=color:#a6e22e>setDefaultApiClient</span>(client);
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> client;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>このクライアントを使って <a href=https://github.com/kubernetes-client/java/tree/master/kubernetes/docs>java/kubernetes/docs/</a> 配下にある api インスタンスを生成する。例えば、cronjob や job を扱うならば <code>BatchV1Api</code> というドキュメントがある。BatchApi だけでも3つのドキュメントがあるのでちょっとやり過ぎな気もする。</p><ul><li>BatchApi.md</li><li>BatchV1Api.md</li><li>BatchV1beta1Api.md</li></ul><p>kubectl コマンドで使う cronjob から手動で job を設定するのを実装してみる。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl create job --from<span style=color:#f92672>=</span>cronjob/my-schedule-job my-manual-job
</span></span></code></pre></div><p>細かい設定はちゃんと調べないといけないけど、一応はこれで動いた。cronjob のオブジェクトを取得して job のオブジェクトを生成して create するだけ。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span><span style=color:#66d9ef>var</span> api <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> BatchV1Api(<span style=color:#66d9ef>this</span>.<span style=color:#a6e22e>getKubernetesClient</span>());
</span></span><span style=display:flex><span><span style=color:#66d9ef>var</span> cronJob <span style=color:#f92672>=</span> api.<span style=color:#a6e22e>readNamespacedCronJob</span>(cronJobName, NAMESPACE_DEFAULT, <span style=color:#66d9ef>null</span>);
</span></span><span style=display:flex><span><span style=color:#66d9ef>var</span> ann <span style=color:#f92672>=</span> Map.<span style=color:#a6e22e>of</span>(<span style=color:#e6db74>&#34;cronjob.kubernetes.io/instantiate&#34;</span>, <span style=color:#e6db74>&#34;manual&#34;</span>);
</span></span><span style=display:flex><span><span style=color:#66d9ef>var</span> metadata <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> V1ObjectMeta().<span style=color:#a6e22e>name</span>(newJobName).<span style=color:#a6e22e>annotations</span>(ann);
</span></span><span style=display:flex><span><span style=color:#66d9ef>var</span> spec <span style=color:#f92672>=</span> cronJob.<span style=color:#a6e22e>getSpec</span>().<span style=color:#a6e22e>getJobTemplate</span>().<span style=color:#a6e22e>getSpec</span>();
</span></span><span style=display:flex><span>spec.<span style=color:#a6e22e>setTtlSecondsAfterFinished</span>(10);
</span></span><span style=display:flex><span><span style=color:#66d9ef>var</span> job <span style=color:#f92672>=</span> <span style=color:#66d9ef>new</span> V1Job()
</span></span><span style=display:flex><span>        .<span style=color:#a6e22e>apiVersion</span>(cronJob.<span style=color:#a6e22e>getApiVersion</span>())
</span></span><span style=display:flex><span>        .<span style=color:#a6e22e>kind</span>(<span style=color:#e6db74>&#34;Job&#34;</span>)
</span></span><span style=display:flex><span>        .<span style=color:#a6e22e>spec</span>(cronJob.<span style=color:#a6e22e>getSpec</span>().<span style=color:#a6e22e>getJobTemplate</span>().<span style=color:#a6e22e>getSpec</span>())
</span></span><span style=display:flex><span>        .<span style=color:#a6e22e>metadata</span>(metadata);
</span></span><span style=display:flex><span><span style=color:#66d9ef>var</span> result <span style=color:#f92672>=</span> api.<span style=color:#a6e22e>createNamespacedJob</span>(NAMESPACE_DEFAULT, job, <span style=color:#66d9ef>null</span>, <span style=color:#66d9ef>null</span>, <span style=color:#66d9ef>null</span>, <span style=color:#66d9ef>null</span>);
</span></span></code></pre></div><p>手動で作成した job の pod は終了後にゴミとして残ってしまうので ttl を設定すれば自動的に削除できることに気付いた。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=display:flex><span>spec.<span style=color:#a6e22e>setTtlSecondsAfterFinished</span>(10);
</span></span></code></pre></div><p>k8s クラスターの内部、つまり pod 内からリクエストするには <a href=https://kubernetes.io/docs/reference/access-authn-authz/rbac/#service-account-permissions>ServiceAccount permissions</a> を適切に設定しないといけない。ひとまずローカルの minikube で super user 権限にしたらリクエストはできた。実運用では適切なロールを定義して適切に権限設定しないといけない。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl create clusterrolebinding serviceaccounts-cluster-admin <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --clusterrole<span style=color:#f92672>=</span>cluster-admin <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --group<span style=color:#f92672>=</span>system:serviceaccounts
</span></span></code></pre></div></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0804/>Kubernetes Clients の調査</a></h1><div class=post-meta><time class=post-date>2022-08-04</time></div><span class=post-tags>#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;</span><div class=post-content><p>23時に寝て6時に起きた。</p><h2 id=k8s-cronjob-の手動実行>k8s cronjob の手動実行</h2><p>いろんな定期／バッチ処理を k8s の cronjob に置き換えつつある。これまでアプリケーションサーバーでスケジュール実行していたものも本来サーバーである必要はないのでサーバーアプリケーションから cli アプリケーションに移行したりしている。そうやって定期実行ジョブが増えてくると、今度は調査やデバッグ目的で任意のタイミングで実行したくなる。kubectl を使って次のように実行できる。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl create job --from<span style=color:#f92672>=</span>cronjob/my-schedule-job my-manual-job
</span></span></code></pre></div><p>この cli を実行すると、cronjob のマニフェストから <code>my-manual-job</code> というジョブの pod が生成されて実行される。開発者ならこれでよいのだけど、非開発者も調査や検証目的で実行したい。そのためには非開発者向けのインターフェースを作らないといけない。本当は chatops のように slack apps によるコマンド実行ができるとカッコよいのだけど、k8s クラスターと slack 間の認証やセキュリティの仕組みを作る必要があって、既存の仕組みがないならそこはセキュリティリスクにも成り得るのでちょっと控えたい。そうすると、既存のサーバーアプリケーションの web api のインターフェースで提供できるようにしたい。複数の言語向けに <a href=https://github.com/kubernetes-client>Kubernetes Clients</a> が提供されている。これを使って cronjob の手動実行を実装できそうな気がする。時間があれば週末に軽く調べてみようと思う。</p><ul><li>python</li><li>c#</li><li>javascript</li><li>java</li><li>c</li><li>haskel</li><li>go</li><li>ruby</li></ul></div></article><article class="post on-list"><h1 class=post-title><a href=/diary/posts/2022/0720/>ノードグループと nodeSelector</a></h1><div class=post-meta><time class=post-date>2022-07-20</time></div><span class=post-tags>#<a href=/diary/tags/kubernetes/>kubernetes</a>&nbsp;</span><div class=post-content><p>1時に寝て6時に起きた。</p><h2 id=eks-クラスターのノードグループと-k8s-の-nodeselector>EKS クラスターのノードグループと k8s の nodeSelector</h2><p>先日 <a href=/diary/posts/2022/0711/>k8s の nodeSelector</a> の調査について書いた。いまテスト環境でその調査結果の運用検証中。当初は k8s の機能だけを使いたいと考えていたが、いま eksctl コマンドで EKS クラスターを管理していて、k8s ノードの実体である ec2 のプロビジョニングはノードグループがもつ起動テンプレートとオートスケールポリシーにより制御される。そのため、ノードグループを分割してそれぞれにノードラベルが必ず付与されるように管理する方が簡単だとわかってきた。要はアプリケーションサーバー向けのノードグループとバッチ処理向けのノードグループの2つを作った。あと覚えておくとよいのが、<a href=https://eksctl.io/usage/iam-policies/#adding-a-custom-instance-role>Adding a custom instance role</a> で任意のポリシーもノードグループの iam ロールに追加できる。設定例としてはこんな感じ。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yml data-lang=yml><span style=display:flex><span>  <span style=color:#f92672>iam</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>attachPolicyARNs</span>:
</span></span><span style=display:flex><span>    - <span style=color:#ae81ff>arn:aws:iam::${accountId}:policy/my-custom-policy</span>
</span></span><span style=display:flex><span>    - <span style=color:#ae81ff>arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly</span>
</span></span><span style=display:flex><span>    - <span style=color:#ae81ff>arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy</span>
</span></span><span style=display:flex><span>    - <span style=color:#ae81ff>arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy</span>
</span></span><span style=display:flex><span>    - <span style=color:#ae81ff>arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore</span>
</span></span></code></pre></div><p>ノードグループの準備が整ったら nodeSelector を指定した pod をデプロイするだけ。k8s ノードがどんなノードラベルをもっているかは次のようにして確認できる。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get node --show-labels
</span></span></code></pre></div><p>意図したノードラベルが付与された k8s ノードに pod がデプロイされたかどうかは次のようにして確認できる。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get pod --output wide --field-selector spec.nodeName<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>ノードラベルをもつノード名<span style=color:#e6db74>}</span>
</span></span></code></pre></div><p>これらの環境構築、検証、wiki にドキュメントを書いて本番作業手順もまとめた。一通りきれいにまとまったインフラ作業を完遂できて気分がよい。</p></div></article><div class=pagination><div class=pagination__buttons><a href=/diary/tags/kubernetes/page/2/ class="button next"><span class=button__text>過去の日記</span>
<span class=button__icon>→</span></a></div></div></div></div><footer class=footer><div class=footer__inner><div class="copyright copyright--user"><span>© 2021 Tetsuya Morimoto</span>
<span>:: <a href=https://github.com/panr/hugo-theme-terminal target=_blank>Theme</a> made by <a href=https://github.com/panr target=_blank>panr</a></span></div></div></footer><script type=text/javascript src=/diary/bundle.min.js></script></div></body></html>